{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import pickle \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.tree import plot_tree\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (BertTokenizer, BertForSequenceClassification, DistilBertTokenizer, DistilBertForSequenceClassification,\n",
    "                          RobertaTokenizer, RobertaForSequenceClassification, ElectraTokenizer, ElectraForSequenceClassification,\n",
    "                          AutoTokenizer, AutoModelForSequenceClassification,AdamW)\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm  # For the progress bar\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Functions defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "def label_mapper(label):\n",
    "    # BENIGN, web_attack, ddos, botnet, infiltration, dos, ssh_bruteforce, ftp_bruteforce, others\n",
    "    if label == 'Benign':\n",
    "        return 0\n",
    "    elif label.startswith(\"Brute Force\"):\n",
    "        return 1\n",
    "    elif label.startswith(\"DDoS\") or label.startswith(\"DDOS\"):\n",
    "        return 2\n",
    "    elif label.startswith(\"Bot\"):\n",
    "        return 3\n",
    "    elif label.startswith(\"Infilteration\") :\n",
    "        return 4\n",
    "    elif label.startswith(\"DoS\"):\n",
    "        return 5\n",
    "    elif label.startswith(\"SSH\"):\n",
    "        return 6\n",
    "    elif label.startswith(\"FTP\"):\n",
    "        return 7\n",
    "    elif label.startswith(\"SQL\"):\n",
    "        return 8\n",
    "    else:\n",
    "        return 9\n",
    "    \n",
    "\n",
    "def dataset_cleaner(df, label_column):\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    Clean the dataset by handling missing values, scaling numerical features, and \n",
    "    applying one-hot encoding to categorical features, while leaving the label class intact.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame, the input DataFrame.\n",
    "    - label_column: str, the name of the target (label) column to be preserved.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with cleaned features and the label column intact.\n",
    "    \"\"\"   \n",
    "    # Separate label column from features\n",
    "    label = df[label_column]\n",
    "    df = df.drop(columns=[label_column])\n",
    "    \n",
    "    # Drop all inf and other NaN values\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "    # Define numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # 1. Handle numerical columns (impute missing values and scale)\n",
    "    if numerical_cols:\n",
    "        # Imputation for numerical columns\n",
    "        numerical_imputer = SimpleImputer(strategy='mean')\n",
    "        df[numerical_cols] = numerical_imputer.fit_transform(df[numerical_cols])\n",
    "\n",
    "        # Scaling numerical columns\n",
    "        scaler = StandardScaler()\n",
    "        df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "\n",
    "    if categorical_cols:\n",
    "        # 2. Handle categorical columns (impute missing values and apply one-hot encoding)\n",
    "        # Imputation for categorical columns\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        df[categorical_cols] = categorical_imputer.fit_transform(df[categorical_cols])\n",
    "\n",
    "        df = pd.get_dummies(df)\n",
    "        print(\"hot enconding done\")\n",
    "\n",
    "    # Re-add the label column\n",
    "    df[label_column] = label\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_target_features(df, test_size = 0.30):\n",
    "    X = df.drop(['Label'], axis=1)\n",
    "    y = df['Label']\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_fix(df):\n",
    "    df['Label'] = df['Attack'].apply(label_mapper)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def select_features_correlation(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Select top k features based on correlation with the target.\n",
    "\n",
    "    Parameters:\n",
    "    - X: DataFrame, the feature matrix.\n",
    "    - y: Series, the target variable.\n",
    "    - k: int, number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features based on correlation.\n",
    "    \"\"\"\n",
    "    # Factorize the target and convert to pandas Series\n",
    "    y_factorized = pd.Series(y.factorize()[0], index=y.index)\n",
    "    \n",
    "    # Convert categorical features to numeric\n",
    "    X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation = X_encoded.corrwith(y_factorized)\n",
    "    \n",
    "    # Create a DataFrame for correlation values\n",
    "    correlation_df = pd.DataFrame({\n",
    "        'Feature': correlation.index,\n",
    "        'Correlation': correlation.values\n",
    "    }).sort_values(by='Correlation', key=abs, ascending=False)\n",
    "    \n",
    "    # Select top k features\n",
    "    return correlation_df.head(k)['Feature'].tolist()\n",
    "\n",
    "def select_features_information_gain(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Select top k features based on information gain with the target.\n",
    "\n",
    "    Parameters:\n",
    "    - X: DataFrame, the feature matrix.\n",
    "    - y: Series, the target variable.\n",
    "    - k: int, number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features based on information gain.\n",
    "    \"\"\"\n",
    "    # Convert categorical features to numeric\n",
    "    X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Calculate information gain\n",
    "    info_gain = mutual_info_classif(X_encoded, y, discrete_features='auto', random_state=42)\n",
    "    \n",
    "    # Create a DataFrame for information gain values\n",
    "    info_gain_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Information Gain': info_gain\n",
    "    }).sort_values(by='Information Gain', ascending=False)\n",
    "    \n",
    "    # Select top k features\n",
    "    return info_gain_df.head(k)['Feature'].tolist()\n",
    "\n",
    "def get_top_features_across_files(file_paths, label_column, k=10):\n",
    "    \"\"\"\n",
    "    Get top k features across multiple files, based on both correlation and information gain.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths: list of file paths.\n",
    "    - label_column: name of the label column.\n",
    "    - k: number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features consistent across all files.\n",
    "    \"\"\"\n",
    "    feature_counter = Counter()\n",
    "    idx = 1\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop(columns=[label_column])\n",
    "        y = df[label_column]\n",
    "        \n",
    "        # Select top features using both methods\n",
    "        top_corr_features = select_features_correlation(X, y, k)\n",
    "        top_ig_features = select_features_information_gain(X, y, k)\n",
    "        \n",
    "        # Combine and count features\n",
    "        feature_counter.update(top_corr_features + top_ig_features)\n",
    "        print(\"File \"+str(idx)+\" done.\")\n",
    "        idx = idx+1\n",
    "    \n",
    "    # Get most common features across files\n",
    "    most_common_features = feature_counter.most_common(k)\n",
    "    return [feature for feature, _ in most_common_features]\n",
    "\n",
    "def keep_selected_features(df, selected_features, label_column):\n",
    "    \"\"\"\n",
    "    Keep only the selected features in the given DataFrame, while leaving the label column intact.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame, the input DataFrame.\n",
    "    - selected_features: list of feature names to keep.\n",
    "    - label_column: str, the name of the target (label) column to be preserved.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with only the selected features and the label column.\n",
    "    \"\"\"\n",
    "    # Extract the label column\n",
    "    label = df[label_column]\n",
    "    \n",
    "    # Drop the label column from the selected features if it's included\n",
    "    if label_column in selected_features:\n",
    "        selected_features.remove(label_column)\n",
    "    \n",
    "    # Keep only the selected features\n",
    "    updated_df = df[selected_features]\n",
    "    \n",
    "    # Re-add the label column\n",
    "    updated_df[label_column] = label\n",
    "    \n",
    "    return updated_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = ['Attack', 'TCP_WIN_MAX_IN', 'TCP_FLAGS', 'L7_PROTO', 'MAX_IP_PKT_LEN', 'LONGEST_FLOW_PKT', 'MAX_TTL', 'MIN_TTL', 'SERVER_TCP_FLAGS', 'FLOW_DURATION_MILLISECONDS', 'CLIENT_TCP_FLAGS', 'PROTOCOL', 'DNS_TTL_ANSWER', 'DNS_QUERY_ID', 'MIN_IP_PKT_LEN', 'DNS_QUERY_TYPE', 'SHORTEST_FLOW_PKT', 'DURATION_OUT', 'DURATION_IN']\n",
    "top_features.remove('Attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature to Strings Convertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_conversion(df, label_column, format_type=\"concatenated\"):\n",
    "        \"\"\"\n",
    "        Converts numerical data into textual representations and optionally concatenates them with labels.\n",
    "\n",
    "        Parameters:\n",
    "        df (DataFrame): The input DataFrame containing features and labels.\n",
    "        label_column (str): The name of the label column.\n",
    "        format_type (str): The format for conversion. Options:\n",
    "                        - \"concatenated\": Concatenate feature values with underscores.\n",
    "                        - \"key_value\": Convert feature-value pairs into text (e.g., feature1: 23.5).\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: A DataFrame with transformed features and labels.\n",
    "        \"\"\"\n",
    "        # Select non-label columns\n",
    "        non_label_columns = df.drop(columns=[label_column]).columns\n",
    "\n",
    "        if format_type == \"concatenated\":\n",
    "            # Convert numerical values to strings and concatenate them with underscores\n",
    "            df['transformed'] = df[non_label_columns].astype(str).apply(lambda row: '_'.join(row), axis=1)\n",
    "\n",
    "        elif format_type == \"key_value\":\n",
    "            # Convert each feature-value pair into key-value text\n",
    "            df['transformed'] = df[non_label_columns].apply(\n",
    "                lambda row: ' '.join([f\"{col}: {row[col]}\" for col in non_label_columns]), axis=1\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid format_type. Choose either 'concatenated' or 'key_value'.\")\n",
    "\n",
    "        # Add the label column to the result\n",
    "        relevant_columns = ['transformed', label_column]\n",
    "        updated_df = df[relevant_columns]\n",
    "\n",
    "        return updated_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Load & Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADED FILE , STARTING CLEANUP\n",
      "\n",
      "                                         transformed  Label\n",
      "0  TCP_WIN_MAX_IN: -0.5945997975478896 TCP_FLAGS:...      0\n",
      "1  TCP_WIN_MAX_IN: -0.15685586920893607 TCP_FLAGS...      0\n",
      "2  TCP_WIN_MAX_IN: -0.5945997975478896 TCP_FLAGS:...      0\n",
      "3  TCP_WIN_MAX_IN: -0.5945997975478896 TCP_FLAGS:...      0\n",
      "4  TCP_WIN_MAX_IN: -0.15685586920893607 TCP_FLAGS...      0\n",
      "CLEANUP DONE, STARTING SPLIT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dataset/downsampled/final_downsampled_dataset.csv')   \n",
    "\n",
    "print(f\"LOADED FILE , STARTING CLEANUP\\n\")\n",
    "\n",
    "#df =label_fix(df)\n",
    "df.rename(columns={'Attack': 'Label'}, inplace=True)\n",
    "\n",
    "\n",
    "#df = keep_selected_features(df,top_features,\"Label\")\n",
    "    \n",
    "df = dataset_cleaner(df,\"Label\")\n",
    "\n",
    "#df = string_conversion(df,\"Label\",\"concatenated\")  \n",
    "df = string_conversion(df,\"Label\",\"key_value\")\n",
    "print(df.head())  \n",
    " \n",
    "print(f\"CLEANUP DONE, STARTING SPLIT\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "# Train-test split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['transformed'], df['label_encoded'], test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configuration\n",
    "def load_model_and_tokenizer(model_name, num_classes):\n",
    "    if model_name == \"bert\":\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_classes)\n",
    "    elif model_name == \"distilbert\":\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_classes)\n",
    "    elif model_name == \"roberta\":\n",
    "        tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "        model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_classes)\n",
    "    elif model_name == \"electra\":\n",
    "        tokenizer = ElectraTokenizer.from_pretrained('google/electra-base-discriminator')\n",
    "        model = ElectraForSequenceClassification.from_pretrained('google/electra-base-discriminator', num_labels=num_classes)\n",
    "    elif model_name == \"spanbert\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('SpanBERT/spanbert-base-cased')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('SpanBERT/spanbert-base-cased', num_labels=num_classes)\n",
    "    elif model_name == \"codebert\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('microsoft/codebert-base', num_labels=num_classes)\n",
    "    elif model_name == \"gpt2\":\n",
    "        # Load GPT-2 tokenizer and add padding token\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Use the EOS token as the padding token \n",
    "        model = GPT2ForSequenceClassification.from_pretrained(\n",
    "            \"gpt2\", \n",
    "            num_labels=num_classes)\n",
    "        model.config.pad_token_id = tokenizer.pad_token_id\n",
    "    elif model_name == \"gpt-neo\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-neo-1.3B')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('EleutherAI/gpt-neo-1.3B', num_labels=num_classes)\n",
    "    elif model_name == \"gpt-j\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('EleutherAI/gpt-j-6B')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('EleutherAI/gpt-j-6B', num_labels=num_classes)\n",
    "    elif model_name == \"opt\":\n",
    "        tokenizer = AutoTokenizer.from_pretrained('facebook/opt-350m')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained('facebook/opt-350m', num_labels=num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name. Choose from: bert, distilbert, roberta, electra, spanbert, codebert, gpt2, gpt-neo, gpt-j, opt\")\n",
    "\n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "model_name = \"bert\" #Change this to select different models: bert, distilbert, roberta, electra, spanbert, codebert\n",
    "num_classes = len(label_encoder.classes_)\n",
    "tokenizer, model = load_model_and_tokenizer(model_name, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts.iloc[idx]\n",
    "        label = self.labels.iloc[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[0 1 2 3 4 5 6 7 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = TextDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = TextDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "print(num_classes)\n",
    "print(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device):\n",
    "    model = model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\", total=len(data_loader))\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        # Update progress bar with the loss\n",
    "        progress_bar.set_postfix(loss=total_loss / (total + len(labels)), accuracy=correct / total)\n",
    "\n",
    "    # Return average loss and accuracy\n",
    "    return total_loss / len(data_loader), correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conf_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(all_labels, all_preds, save_path=None, title=None):\n",
    "    \"\"\"\n",
    "    Generates and plots the confusion matrix using the classes from all_labels and all_preds.\n",
    "    Optionally, adds a title and saves the plot to the specified file path.\n",
    "\n",
    "    Parameters:\n",
    "    - all_labels: list of true labels\n",
    "    - all_preds: list of predicted labels\n",
    "    - save_path: str (optional) path to save the confusion matrix plot (e.g., 'confusion_matrix.png')\n",
    "    - title: str (optional) title for the plot\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    unique_labels = list(set(all_labels))\n",
    "\n",
    "    # Display confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=unique_labels)\n",
    "    disp.plot(cmap=\"Blues\", xticks_rotation='vertical')\n",
    "\n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    # If a save path is provided, save the plot\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrix saved to: {save_path}\")\n",
    "    else:\n",
    "        plt.show()  # If no save path, show the plot instead\n",
    "\n",
    "    plt.close()  # Close the plot to avoid memory issues if running multiple times\n",
    "    \n",
    "    return cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data_loader, device, label_encoder,epoch,model_name):\n",
    "    model = model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    progress_bar = tqdm(data_loader, desc=\"Evaluating\", total=len(data_loader))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            # Append labels and predictions as lists\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "            # Update the progress bar with the current loss and accuracy\n",
    "            progress_bar.set_postfix(loss=total_loss / (total + len(labels)), accuracy=correct / total)\n",
    "\n",
    "    # Ensure all_preds and all_labels are iterable\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Plot the confusion matrix using classes from all_labels and all_preds\n",
    "    cm_title = model_name + \"_epoch_\" + str(epoch)\n",
    "    cm = plot_confusion_matrix(all_labels, all_preds,title=cm_title)\n",
    "\n",
    "    # Calculate metrics directly\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "    recall = recall_score(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "    f1 = f1_score(all_labels, all_preds, average=None, labels=np.unique(all_labels))\n",
    "\n",
    "    # You can calculate overall or per-class metrics\n",
    "    overall_precision = np.mean(precision)\n",
    "    overall_recall = np.mean(recall)\n",
    "    overall_f1 = np.mean(f1)\n",
    "\n",
    "    # Prepare metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"overall_precision\": overall_precision,\n",
    "        \"overall_recall\": overall_recall,\n",
    "        \"overall_f1\": overall_f1\n",
    "    }\n",
    "\n",
    "    # Return total loss, accuracy, and metrics\n",
    "    return total_loss / len(data_loader), correct / total, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\modeling_utils.py:3157\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3152\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3154\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3155\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3156\u001b[0m         )\n\u001b[1;32m-> 3157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1691/1691 [05:31<00:00,  5.11it/s, accuracy=0.946, loss=0.0131]\n",
      "Evaluating: 100%|██████████| 725/725 [00:56<00:00, 12.87it/s, accuracy=0.957, loss=0.0104]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgwAAAHCCAYAAACDjJFWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABh7UlEQVR4nO3deXwMdx8H8M9uIgc5SJBIRMSZkLjiipum4qijlNIg1PGURB2laJ2lUtRdd+s+Sls87lIqriCiQZW4gqBJEMlKyCE7zx+ebG1zbmazs2M/777m9erO/Gbms9NUvn6/38woBEEQQERERJQPpdQBiIiIyPixYCAiIqICsWAgIiKiArFgICIiogKxYCAiIqICsWAgIiKiArFgICIiogKxYCAiIqICsWAgIiKiArFgoLfC9OnToVAo8OTJE6mjyJpCoUBISIjUMYjICLFgINLR8uXLsX79eqljGL3t27ejX79+qF69OhQKBdq0aSN1JCISgQUDkY5YMBTOihUr8N///hdubm4oU6aM1HGISCRzqQMQycWLFy9QsmRJqWPIxqZNm+Dq6gqlUglvb2+p4xCRSOxhoLfKkydP0Lt3b9jZ2cHR0RGjRo1CWlqaVpvNmzfD19cX1tbWcHBwQJ8+fRAbG6vVpk2bNvD29kZkZCRatWqFkiVL4osvvkDlypVx9epVhIWFQaFQFKmrXdfzN2vWDNbW1vDw8MDKlStzHC8hIQGDBw+Gk5MTrKysULduXWzYsCFHO7VajcWLF8PHxwdWVlYoV64cOnTogAsXLuRou3v3bnh7e8PS0hK1a9fGoUOHdPqOAODm5galkn/EEL0t+H8zvVV69+6NtLQ0hIaGolOnTliyZAmGDRum2f71119jwIABqF69OhYsWIDRo0fj6NGjaNWqFZKSkrSO9fTpU3Ts2BH16tXDokWL0LZtWyxatAgVK1aEp6cnNm3ahE2bNuHLL78sdD5dzv/s2TN06tQJvr6+mDt3LipWrIjhw4dj7dq1mjYvX75EmzZtsGnTJgQGBmLevHmwt7fHwIEDsXjxYq3jDR48GKNHj4abmxvmzJmDiRMnwsrKCmfPntVqd+rUKYwYMQJ9+vTB3LlzkZaWhp49e+Lp06eF/p5E9BYSiN4C06ZNEwAIXbt21Vo/YsQIAYBw6dIl4e7du4KZmZnw9ddfa7W5cuWKYG5urrW+devWAgBh5cqVOc5Vu3ZtoXXr1jpnLMr558+fr1mXnp4u1KtXTyhfvryQkZEhCIIgLFq0SAAgbN68WdMuIyND8PPzE2xsbASVSiUIgiAcO3ZMACB8+umnOXKp1WrNvwMQLCwshFu3bmnWXbp0SQAgLF26VOfvnK2o14yIjAd7GOitEhwcrPV55MiRAIADBw5g586dUKvV6N27N548eaJZnJ2dUb16dfz+++9a+1paWmLQoEF6y6br+c3NzfGf//xH89nCwgL/+c9/kJCQgMjISM33cnZ2Rt++fTXtSpQogU8//RQpKSkICwsDAPzyyy9QKBSYNm1ajlwKhULrs7+/P6pWrar5XKdOHdjZ2eHOnTviLwIRyRYnPdJbpXr16lqfq1atCqVSibt370KpVEIQhBxtspUoUULrs6urKywsLPSW7ebNmzqd38XFBaVKldJaV6NGDQDA3bt30bRpU9y7dw/Vq1fPMVfAy8sLAHDv3j0AwO3bt+Hi4gIHB4cCc1aqVCnHujJlyuDZs2cF7ktEby8WDPRWe/Nvz2q1GgqFAgcPHoSZmVmOtjY2Nlqfra2t9ZpF1/NLJbdsACAIgoGTEJExYcFAb5WbN2/Cw8ND8/nWrVtQq9WoXLkyzMzMIAgCPDw8NH9TL4p/d+EXVtWqVXU6/6NHj5CamqrVy3Djxg0AQOXKlQEA7u7uuHz5MtRqtVYvw/Xr1zXbs8/966+/IjExsVC9DERE/8Y5DPRWWbZsmdbnpUuXAgA6duyIHj16wMzMDDNmzMjxt2VBEAp9F0CpUqVy3NFQGLqe/9WrV1i1apXmc0ZGBlatWoVy5crB19cXANCpUyfExcVh+/btWvstXboUNjY2aN26NQCgZ8+eEAQBM2bMyJGLPQdEVBjsYaC3SkxMDLp27YoOHTogPDwcmzdvxkcffYS6desCAGbNmoVJkybh7t276N69O2xtbRETE4Ndu3Zh2LBhGDduXIHn8PX1xYoVKzBr1ixUq1YN5cuXR7t27Qrcr2rVqjqd38XFBXPmzMHdu3dRo0YNbN++HVFRUVi9erVmvsOwYcOwatUqDBw4EJGRkahcuTJ+/vlnnD59GosWLYKtrS0AoG3btujfvz+WLFmCmzdvokOHDlCr1Th58iTatm1bLO+POHHiBE6cOAEAePz4MVJTUzFr1iwAQKtWrdCqVSu9n5OIipFEd2cQ6VX2bZV//fWX8MEHHwi2trZCmTJlhJCQEOHly5dabX/55RehRYsWQqlSpYRSpUoJnp6eQnBwsBAdHa1p07p1a6F27dq5nisuLk7o3LmzYGtrKwDQ+XZBXc5/4cIFwc/PT7CyshLc3d2F7777Lsfx4uPjhUGDBglly5YVLCwsBB8fH2HdunU52r169UqYN2+e4OnpKVhYWAjlypUTOnbsKERGRmraABCCg4Nz7Ovu7i4EBQXp9D2z/5vktkybNk2nYxGR9BSCwP5IImPTpk0bPHnyBH/++afUUYiIAHAOAxERERUC5zAQ6UFcXFy+262trWFvb2+gNMUnKysLjx8/zreNjY2N0dwiSkT6w4KBSA8qVKiQ7/agoKC34pXYsbGxWret5mbatGmYPn26YQIRkcFwDgORHvz222/5bndxcUGtWrUMlKb4pKWl4dSpU/m2qVKlCqpUqWKgRERkKCwYiIiIqECc9EhEREQFkvUcBrVajUePHsHW1rbIj+slIiLpCIKA58+fw8XFJcdL1PQpLS0NGRkZoo9jYWEBKysrPSSSH1kXDI8ePYKbm5vUMYiISKTY2FhUrFixWI6dlpYGa1tH4NUL0cdydnZGTEyMSRYNsi4Ysh97a1ErCAoz/b2G2BDuH/9W6ghERJJ7rlKhmoeb5s/z4pCRkQG8egHLWkGAmN8VWRmI+2sDMjIyWDDITfYwhMLMQnYFg52dndQRiIiMhkGGlc2tRP2uEBSmPe1P1gUDERFRoSkAiClMTHyqnGmXS0RERFQo7GEgIiLToFC+XsTsb8JYMBARkWlQKEQOSZj2mIRpl0tERGQ6snsYxCw6OHHiBLp06QIXFxcoFArs3r1ba7sgCJg6dSoqVKgAa2tr+Pv74+bNm1ptEhMTERgYCDs7O5QuXRqDBw9GSkqKVpvLly+jZcuWsLKygpubG+bOnZsjy08//QRPT09YWVnBx8cHBw4c0Om7ACwYiIiIikVqairq1q2LZcuW5bp97ty5WLJkCVauXIlz586hVKlSCAgIQFpamqZNYGAgrl69iiNHjmDfvn04ceIEhg0bptmuUqnQvn17uLu7IzIyEvPmzcP06dOxevVqTZszZ86gb9++GDx4MP744w90794d3bt3x59//qnT95H1uyRUKhXs7e1h6TNUdrdVPov4TuoIRESSU6lUcHK0R3JycrHdbq75XeE7EgozyyIfR8hKR3rk0iJlVSgU2LVrF7p37/76WIIAFxcXfPbZZxg3bhwAIDk5GU5OTli/fj369OmDa9euoVatWoiIiEDDhg0BAIcOHUKnTp3w4MEDuLi4YMWKFfjyyy8RFxcHC4vXvwcnTpyI3bt34/r16wCADz/8EKmpqdi3b58mT9OmTVGvXj2sXLmy0N+BPQxERGQixA5HvP6VqVKptJb09HSdk8TExCAuLg7+/v6adfb29mjSpAnCw8MBAOHh4ShdurSmWAAAf39/KJVKnDt3TtOmVatWmmIBAAICAhAdHY1nz55p2rx5nuw22ecpLBYMREREOnBzc4O9vb1mCQ0N1fkYcXFxAAAnJyet9U5OTpptcXFxKF++vNZ2c3NzODg4aLXJ7RhvniOvNtnbC4t3SRARkWnQ010SsbGxWkMSlpZFH+aQE/YwEBGRadDTXRJ2dnZaS1EKBmdnZwBAfHy81vr4+HjNNmdnZyQkJGhtf/XqFRITE7Xa5HaMN8+RV5vs7YXFgoGIiMjAPDw84OzsjKNHj2rWqVQqnDt3Dn5+fgAAPz8/JCUlITIyUtPm2LFjUKvVaNKkiabNiRMnkJmZqWlz5MgR1KxZE2XKlNG0efM82W2yz1NYLBiIiMg0ZA9JiFl0kJKSgqioKERFRQF4PdExKioK9+/fh0KhwOjRozFr1izs2bMHV65cwYABA+Di4qK5k8LLywsdOnTA0KFDcf78eZw+fRohISHo06cPXFxcAAAfffQRLCwsMHjwYFy9ehXbt2/H4sWLMXbsWE2OUaNG4dChQ5g/fz6uX7+O6dOn48KFCwgJCdHp+3AOAxERmQYDPxr6woULaNu2reZz9i/xoKAgrF+/Hp9//jlSU1MxbNgwJCUloUWLFjh06JDWq7O3bNmCkJAQvPPOO1AqlejZsyeWLFmi2W5vb4/Dhw8jODgYvr6+KFu2LKZOnar1rIZmzZph69atmDx5Mr744gtUr14du3fvhre3t25f/215DkPzhl4Y2d8fdT0roUI5ewSOW40DYZeL9fxDerXCyH7voLyjHf68+RAT5v2Ei3/dy7XtT4uHw79ZbU2u4noOw5odYVi6+SgSnqrgXd0Vc8b3gm/tysVyrqI4ffEWlm76DZeu30fcExU2zxuKzm3qaranvEjHjO/+iwNhl5GYnAp3F0cM+7A1Pu7ZUsLUeTP2650fuWZnbsMq7twGfQ5Dk/FQmIt4DsOrdKSfm1esWY3ZWzMkUdLaEn/eeIjxc7fr5Xh932uCvStH5bn9/XcbYNbo9zHn+4No038O/rz5EL8sDUbZMjY52g7v2xaGKMt2Ho7E5EW7MGFIRxzfNAHe1V3Rc+QyPE58XvwnL6QXL9PhXcMV8z7/MNftkxf+gqPhf2HVVwNwbsdkfNKnDT6f91OxF39FIYfrnRe5Zmduw5Jr7jwZeEjibWMUBcOyZctQuXJlWFlZoUmTJjh//rzOx/jtzF/4euU+7D+e+y8WixLm+GrU+7i6fxYenJiPI+vGoXmD6kXOPOKjdti4+wy27j2L6Jg4jA39ES/SMtCvq/YkEu8arggObIeQmZuLfK7CWr71GAZ0b4bArn7wrFIBCyb1QUkrC2zeo9vDOYrTu81rY/LwLnivbd1ct5+7HIO+nZughW8NVHJxxMAeLeBd3TXPnhspyeF650Wu2ZnbsOSaO08GfpfE20byb799+3aMHTsW06ZNw8WLF1G3bl0EBATkuJVErLmf90Jjn8oY8uU6tOgbiv8e/QM/LxmBKm7ldD5WCXMz1PN0w/Hz0Zp1giAg7Hw0Gvl4aNZZW5bAmpkDMX7uDiQ8Ld6KPCPzFaKux6JN45qadUqlEq0b10TElZhiPbc+NanjgYMnruBRQhIEQcDJCzdw+34C2jbxkjqaFjlfb7lmZ27DkmvufCkUIgsG9jBIasGCBRg6dCgGDRqEWrVqYeXKlShZsiTWrl2rt3NUdCqDwPeaYuDEtQiPuo27D5/gu81HcfbSbQR2aarz8RxL28Dc3CxHt9zjRBXKO/4zrjV7bE+cvxyDgyeuiP4OBXmalIKsLDXKOdhqrS/nYIeEp6piP7++zBnfCzWrOKN258ko7zcKH3y6HPM+743mDapJHU2LnK+3XLMzt2HJNTcVH0nvksjIyEBkZCQmTZqkWadUKuHv75/rM67T09O1ntmtUhXuh7ZWNReYm5sh4pepWustLcyRmJwK4HVREb5jsmabuZkSJczNEBs2X7Nu4bpfsWD94UKds2MrH7RsWAOt+31TqPb02urtYbhw5S62zv8P3Co44MwftzB+7g44l7VHmyaeUscjIjlTKl4vYvY3YZIWDE+ePEFWVlauz7jOfsvWm0JDQzFjxgydz1OqpCVevcpC2wFzkJWl1tqW+vJ1AfL3k2S0CvzneeBd2tZDl3b1MGzKes26Z6oXAF5X3q9eZeVbebdsWAMeFcvi7rF5Wm02zhmC8KjbOn+HgjiWtoGZmbLAXg9j9jItAzOX78WmeUMR0OL17T7e1V3x540H+G7zUaMqGOR8veWanbkNS66582Xg2yrfNrL69pMmTUJycrJmiY2NLdR+l6MfwNzcDOXK2CLmwROtJXtuQVaWWmv942fPkZaeqbUu6f8FQ+arLERdj0XrRv+M7SkUCrRqVEMztrdow2G0+CgUrfp9o1kA4IuFvyD4K/1PgLQoYY56nm4Ii/hnXoVarcaJiBta8yqMWearLGS+yoLyX+OESqUSaiO7+1fO11uu2ZnbsOSam4qPpD0MZcuWhZmZWaGfcW1paZnnM7tLWVvA440JjO4ujvCu4Yqk5Be4fT8BOw6ex4rp/TF58S5cjn6AsqVt0LpxTVy9+RCHT1/VOfvyrcewfFp//HHtPi5evYvhfduilLUltuw9CwBIePo814mOD+Ke4f6jpzqfrzBGfNQOI2ZsQn2vSmhQuzJWbPsdqS/TizRPo7ikvEhHTOxjzed7j57iSvQDlLYvCTdnBzRvUA1Tl+yGtVUJuDk74PTFW9h+4Dxmje4hYercyeF650Wu2ZnbsOSaO096evmUqZK0YLCwsICvry+OHj2qeRSmWq3G0aNHdX5kZT0vd+xb9c9zE2aP7QkA2LrvLIJnbEbwjM0YN7gDZo16HxXKl8bTpFRc+DMGv578s0jZdx25iLKlbfDFfzqjvKMtrtx4iA8+lfb+5B7tffEkKQWzV+1HwtPn8Knhip+XBBtV92HUtXvo8sk/Tyn7cuFOAEDfzk2wfHp//PD1x/hq2X8xbMoGPFO9gJuzAyYPfw8f92whVeQ8yeF650Wu2ZnbsOSaO08ckhBF8ic9bt++HUFBQVi1ahUaN26MRYsWYceOHbh+/XqOuQ3/9uaTHhVmFgZKrB/F9aRHIiI5MeiTHltPg8LcquAd8iC8SkN62AyTfdKj5O+S+PDDD/H48WNMnToVcXFxqFevHg4dOlRgsUBERKQTDkmIInnBAAAhISE6D0EQERHphEMSopj2tyciIqJCMYoeBiIiomLHIQlRWDAQEZFp4JCEKCwYiIjINLCHQRTTLpeIiIioUNjDQEREJkLkkISJ/x2bBQMREZkGDkmIYtrlEhERERUKexiIiMg0KBQi75Iw7R4GFgxERGQaeFulKKb97YmIiKhQ2MNARESmgZMeRWHBQEREpoFDEqKY9rcnIiKiQmEPAxERmQYOSYjCgoGIiEwDhyREeSsKhvvHv4WdnZ3UMYiIyJixh0EU0y6XiIiIqFDeih4GIiKigigUCijYw1BkLBiIiMgksGAQh0MSREREVCD2MBARkWlQ/H8Rs78JY8FAREQmgUMS4nBIgoiIiArEHgYiIjIJ7GEQhwUDERGZBBYM4nBIgoiIiArEHgYiIjIJ7GEQhwUDERGZBt5WKQoLBiIiMgnsYRCHcxiIiIioQOxhICIik/D67dZiehj0l0WOWDAQEZFJUEDkkISJVwwckiAiIqICsWD4l9MXb6HPmJXw6vgFyjQKwf7jl6SOpJM1O8JQp+tUODcfDf+B8xB59a7UkQok52sux+udTa7Zmduw5Jo7N9mTHsUspkzSguHEiRPo0qULXFxcoFAosHv3binjAABevEyHdw1XzPv8Q6mj6Gzn4UhMXrQLE4Z0xPFNE+Bd3RU9Ry7D48TnUkfLl1yvuVyvNyDf7MxtWHLNnSeFHhYTJmnBkJqairp162LZsmVSxtDybvPamDy8C95rW1fqKDpbvvUYBnRvhsCufvCsUgELJvVBSSsLbN4TLnW0fMn1msv1egPyzc7chiXX3FQ8JC0YOnbsiFmzZuH999+XMsZbISPzFaKux6JN45qadUqlEq0b10TElRgJk72d5Hy95ZqduQ1LrrnzJXY4gkMS9DZ4mpSCrCw1yjnYaq0v52CHhKcqiVK9veR8veWanbkNS66588M5DOLI6rbK9PR0pKenaz6rVPL8oSUiIpIbWfUwhIaGwt7eXrO4ublJHcloOJa2gZmZMsdkpMeJKpR3tJMo1dtLztdbrtmZ27Dkmjs/7GEQR1YFw6RJk5CcnKxZYmNjpY5kNCxKmKOepxvCIqI169RqNU5E3EAjHw8Jk72d5Hy95ZqduQ1LrrnzxbskRJHVkISlpSUsLS2L9RwpL9IRE/tY8/neo6e4Ev0Ape1Lws3ZoVjPLdaIj9phxIxNqO9VCQ1qV8aKbb8j9WU6Ars0lTpavuR6zeV6vQH5Zmduw5Jr7ryI7SUw9R4GSQuGlJQU3Lp1S/M5JiYGUVFRcHBwQKVKlSTJFHXtHrp8skTz+cuFOwEAfTs3wfLp/SXJVFg92vviSVIKZq/aj4Snz+FTwxU/Lwk2+u5DuV5zuV5vQL7Zmduw5JqbiodCEARBqpMfP34cbdu2zbE+KCgI69evL3B/lUoFe3t7xD9Nhp0df4CJiORGpVLBydEeycnF9+d49u+KcgM2QGlRssjHUWe8wOONQcWa1ZhJ2sPQpk0bSFivEBGRCeGQhDiymvRIRERE0pDVpEciIqKiYg+DOCwYiIjINIi9NdK06wUOSRARERWHrKwsTJkyBR4eHrC2tkbVqlUxc+ZMrbl7giBg6tSpqFChAqytreHv74+bN29qHScxMRGBgYGws7ND6dKlMXjwYKSkpGi1uXz5Mlq2bAkrKyu4ublh7ty5ev8+LBiIiMgkGPpJj3PmzMGKFSvw3Xff4dq1a5gzZw7mzp2LpUuXatrMnTsXS5YswcqVK3Hu3DmUKlUKAQEBSEtL07QJDAzE1atXceTIEezbtw8nTpzAsGHDNNtVKhXat28Pd3d3REZGYt68eZg+fTpWr14t/qK9gUMSRERkEgw9h+HMmTPo1q0bOnfuDACoXLkytm3bhvPnzwN43buwaNEiTJ48Gd26dQMAbNy4EU5OTti9ezf69OmDa9eu4dChQ4iIiEDDhg0BAEuXLkWnTp3w7bffwsXFBVu2bEFGRgbWrl0LCwsL1K5dG1FRUViwYIFWYSEWexiIiIh0oFKptJY3X4r4pmbNmuHo0aO4ceMGAODSpUs4deoUOnbsCOD1wwrj4uLg7++v2cfe3h5NmjRBeHg4ACA8PBylS5fWFAsA4O/vD6VSiXPnzmnatGrVChYWFpo2AQEBiI6OxrNnz/T2vdnDQEREJkFfPQz/fvHhtGnTMH369BztJ06cCJVKBU9PT5iZmSErKwtff/01AgMDAQBxcXEAACcnJ639nJycNNvi4uJQvnx5re3m5uZwcHDQauPh4ZHjGNnbypQpU5SvmwMLBiIiMg16uksiNjZW60mPeb3jaMeOHdiyZQu2bt2qGSYYPXo0XFxcEBQUJCKINFgwEBGRSdBXD4OdnV2hHg09fvx4TJw4EX369AEA+Pj44N69ewgNDUVQUBCcnZ0BAPHx8ahQoYJmv/j4eNSrVw8A4OzsjISEBK3jvnr1ComJiZr9nZ2dER8fr9Um+3N2G33gHAYiIqJi8OLFCyiV2r9mzczMoFarAQAeHh5wdnbG0aNHNdtVKhXOnTsHPz8/AICfnx+SkpIQGRmpaXPs2DGo1Wo0adJE0+bEiRPIzMzUtDly5Ahq1qypt+EIgAUDERGZCEPfVtmlSxd8/fXX2L9/P+7evYtdu3ZhwYIFeP/99zV5Ro8ejVmzZmHPnj24cuUKBgwYABcXF3Tv3h0A4OXlhQ4dOmDo0KE4f/48Tp8+jZCQEPTp0wcuLi4AgI8++ggWFhYYPHgwrl69iu3bt2Px4sUYO3asXq8fhySIiMgkKCBySELHCRBLly7FlClTMGLECCQkJMDFxQX/+c9/MHXqVE2bzz//HKmpqRg2bBiSkpLQokULHDp0CFZWVpo2W7ZsQUhICN555x0olUr07NkTS5Ys0Wy3t7fH4cOHERwcDF9fX5QtWxZTp07V6y2VgMSvtxaLr7cmIpI3Q77e2u0/26G0FPF66/QXiF31IV9vTURE9Dbjy6fEYcFARESmgS+fEoUFA+kk+UVmwY2MlH3JElJHICKSLRYMRERkEjgkIQ4LBiIiMgksGMThcxiIiIioQOxhICIik6BQvF7E7G/KWDAQEZFJeF0wiBmS0GMYGWLBQEREpkFkD4Op31bJOQxERERUIPYwEBGRSeBdEuKwYCAiIpPASY/icEiCiIiICsQeBiIiMglKpQJKZdG7CQQR+74NWDAQEZFJ4JCEOBySICIiogKxh4GIiEwC75IQhwUDERGZBA5JiMMhCSIiIioQexiIiMgkcEhCHBYM//LN6v2Ys+ag1rrq7k44//MUiRLpZs2OMCzdfBQJT1Xwru6KOeN7wbd2ZcnyNP/wKzyMe5Zjff/uzTFzzAdIeKpC6Io9OBl5A6kv0lHFrRxC+r+Ljq3r5tgnPeMVug9fiGu3HmH/9+NQu7qrIb5CvozteutCrtmZ27Dkmjs3LBjEkXRIIjQ0FI0aNYKtrS3Kly+P7t27Izo6WspIAADPKhVw/eBszXLw+zFSRyqUnYcjMXnRLkwY0hHHN02Ad3VX9By5DI8Tn0uWac+qsTi/c4Zm2Tz/EwBApzb1AACfzd6CO7GP8f3swfh13Xh0aFUHwdM34M8bD3IcK3TlHjg52hsyfr6M8XoXllyzM7dhyTV3XrLnMIhZTJmkBUNYWBiCg4Nx9uxZHDlyBJmZmWjfvj1SU1OljAVzMyWcytppFsfSNpLmKazlW49hQPdmCOzqB88qFbBgUh+UtLLA5j3hkmVyLG2D8o52muVo+F9wdy2LpvWqAgAir95FUI8WqOfljkouZTFyQHvY2VjnKBh+P3sNJyOi8eWIrlJ8jVwZ4/UuLLlmZ27DkmtuKh6SFgyHDh3CwIEDUbt2bdStWxfr16/H/fv3ERkZKWUs3Il9DK+OX6Bet2kYOnk9YuMSJc1TGBmZrxB1PRZtGtfUrFMqlWjduCYirsRImOwfGZmvsPtIJHp3bKzp2vOtXRn7fo9CkioVarUae45eRHrGK01BAQCPE59j0rfbsfDLQFhZWkgVX4scrnde5JqduQ1Lrrnzo4BCMyxRpMXE329tVHdJJCcnAwAcHBwky+BbuzKWTeuHn5YEY/7ED3Hv0VN0GroQz1PTJMtUGE+TUpCVpUY5B1ut9eUc7JDwVCVRKm2HT16BKuUlPujYWLPuu+kDkfkqC/W6TEYN//H4cv5PWDVrECpXLAcAEAQB40K3IrBrM9TxrCRV9BzkcL3zItfszG1Ycs2dHw5JiGM0kx7VajVGjx6N5s2bw9vbO9c26enpSE9P13xWqfT/Q/tu89qaf/eu7oqG3pXh02Uqdv92Ef27NdP7+UzJ9gPn0KaxJ5zK/jMPYcEPB6BKeYktC4ajjH0pHD51BcHTN+CnJSPhWdUF6385idSX6RgR6C9hciIiMpqCITg4GH/++SdOnTqVZ5vQ0FDMmDHDgKkAe9uSqFapPO7EPjboeXXlWNoGZmbKHJORHieqUN7RTqJU/3gQl4jTkTewcuYgzbp7D59gw65TOLz+c9TwqAAAqFXNFRGX72Dj7lOY/VlvnPnjJi5evYsa747XOl7X/yxAN/8GWPBFoEG/RzZjv975kWt25jYsuebOD++SEMcohiRCQkKwb98+/P7776hYsWKe7SZNmoTk5GTNEhsbW+zZUl6kI+bhEziXNZ7Z+bmxKGGOep5uCIv45y4TtVqNExE30MjHQ8Jkr/108DwcS9ugXdNamnUv0zIAAEqF9o+hUqmEoBYAANM/7YGDP4zHge/H4cD347BuzlAAwHfTBmD8kM4GSp+TsV/v/Mg1O3Mbllxz54dDEuJI2sMgCAJGjhyJXbt24fjx4/DwyP+H0NLSEpaWlsWaacqinejQ0gduFRzw9+NkfLN6P8yUSvQM8C3W8+rDiI/aYcSMTajvVQkNalfGim2/I/VlOgK7NJU0l1qtxs8Hz6Nnh0YwNzfTrK/q7oTKrmXxxfwd+GJEV5Sxez0kcerCDaz9ZggAwNWpjNaxSlq//u9fyaUsKpQvbbDvkBtjvd6FIdfszG1Ycs1NxUPSgiE4OBhbt27Ff//7X9ja2iIuLg4AYG9vD2tra0kyPUxIwpDJ65CY/AJly9igSd0qOLLuM5QtY1vwzhLr0d4XT5JSMHvVfiQ8fQ6fGq74eUmw5N2HpyJv4GH8M/Tu1ERrfQlzM6ybOwxzVu3DkEnfI/VlBtxdy2L+pL5o+0ZPhLEy1utdGHLNztyGJdfceeGQhDgKQRAEyU6ex8Vft24dBg4cWOD+KpUK9vb2iH+aDDs7ef4Ay03yi0ypIxSZfckSUkcgon9RqVRwcrRHcnLx/Tme/buiwZR9MLMqVeTjZKWl4uLM94o1qzGTfEiCiIiIjJ/R3CVBRERUnDgkIQ4LBiIiMg1i73Qw7XqBBQMREZkG9jCIYxTPYSAiIiLjxh4GIiIyCWIfvmTiHQwsGIiIyDRwSEIcDkkQERFRgdjDQEREJoFDEuKwYCAiIpPAIQlxOCRBREREBWIPAxERmQT2MIjDgoGIiEwC5zCIwyEJIiIiKhB7GIiIyCRwSEIcFgxERGQSOCQhDgsGIiIyCexhEIdzGIiIiKhAb0UPg1otQK0WpI6hE6VSnpWqfckSUkcgIioSBUQOSegtiTy9FQUDERFRQZQKBZQiKgYx+74NOCRBREREBWIPAxERmQTeJSEOCwYiIjIJvEtCHA5JEBERUYHYw0BERCZBqXi9iNnflLFgICIi06AQOaxg4gUDhySIiIioQOxhICIik8C7JMRhwUBERCZB8f9/xOxvyjgkQUREJiF70qOYRVcPHz5Ev3794OjoCGtra/j4+ODChQua7YIgYOrUqahQoQKsra3h7++Pmzdvah0jMTERgYGBsLOzQ+nSpTF48GCkpKRotbl8+TJatmwJKysruLm5Ye7cuUW6RvlhwUBERFQMnj17hubNm6NEiRI4ePAg/vrrL8yfPx9lypTRtJk7dy6WLFmClStX4ty5cyhVqhQCAgKQlpamaRMYGIirV6/iyJEj2LdvH06cOIFhw4ZptqtUKrRv3x7u7u6IjIzEvHnzMH36dKxevVqv34dDEkREZBIM/eCmOXPmwM3NDevWrdOs8/Dw0Py7IAhYtGgRJk+ejG7dugEANm7cCCcnJ+zevRt9+vTBtWvXcOjQIURERKBhw4YAgKVLl6JTp0749ttv4eLigi1btiAjIwNr166FhYUFateujaioKCxYsECrsBCrUAXDnj17Cn3Arl27FjkMERFRcTH0pMc9e/YgICAAvXr1QlhYGFxdXTFixAgMHToUABATE4O4uDj4+/tr9rG3t0eTJk0QHh6OPn36IDw8HKVLl9YUCwDg7+8PpVKJc+fO4f3330d4eDhatWoFCwsLTZuAgADMmTMHz5490+rREKNQBUP37t0LdTCFQoGsrCwxeYiIiIyaSqXS+mxpaQlLS8sc7e7cuYMVK1Zg7Nix+OKLLxAREYFPP/0UFhYWCAoKQlxcHADAyclJaz8nJyfNtri4OJQvX15ru7m5ORwcHLTavNlz8eYx4+LiDFswqNVqvZyMiIhIKvp6vbWbm5vW+mnTpmH69Ok52qvVajRs2BCzZ88GANSvXx9//vknVq5ciaCgoCLnkIqoOQxpaWmwsrLSVxaDy8pSY86aA/jpUAQSEp/Duaw9+nZugs8+DtCMVe39PQrrd57Gpev38Uz1Asc3TYBPjYoSJ8/bmh1hWLr5KBKequBd3RVzxveCb+3KUscqEHMbnlyzM7dhyTV3bvQ1JBEbGws7OzvN+tx6FwCgQoUKqFWrltY6Ly8v/PLLLwAAZ2dnAEB8fDwqVKigaRMfH4969epp2iQkJGgd49WrV0hMTNTs7+zsjPj4eK022Z+z2+iDzndJZGVlYebMmXB1dYWNjQ3u3LkDAJgyZQp++OEHvQUzhMWbjmDdzlOYM64Xwn/8EtOCu2LJ5t+wekeYps2LlxloWrcKpoV0kzBp4ew8HInJi3ZhwpCOOL5pAryru6LnyGV4nPhc6mj5Ym7Dk2t25jYsueYubnZ2dlpLXgVD8+bNER0drbXuxo0bcHd3B/B6AqSzszOOHj2q2a5SqXDu3Dn4+fkBAPz8/JCUlITIyEhNm2PHjkGtVqNJkyaaNidOnEBmZqamzZEjR1CzZk29DUcARSgYvv76a6xfvx5z587VmmDh7e2N77//XqdjrVixAnXq1NFcdD8/Pxw8eFDXSEUWcTkGHVv5oH0Lb1RycUTXd+qjbWNPXPzrnqbNh50aY/yQjmjdqKbBchXV8q3HMKB7MwR29YNnlQpYMKkPSlpZYPOecKmj5Yu5DU+u2ZnbsOSaOy/Zd0mIWXQxZswYnD17FrNnz8atW7ewdetWrF69GsHBwZo8o0ePxqxZs7Bnzx5cuXIFAwYMgIuLi2buoJeXFzp06IChQ4fi/PnzOH36NEJCQtCnTx+4uLgAAD766CNYWFhg8ODBuHr1KrZv347Fixdj7Nixer1+OhcMGzduxOrVqxEYGAgzMzPN+rp16+L69es6HatixYr45ptvEBkZiQsXLqBdu3bo1q0brl69qmusImlUxwMnLtzArfuvu3v+vPEA5y7dgb9frQL2ND4Zma8QdT0WbRr/U9golUq0blwTEVdiJEyWP+Y2PLlmZ27Dkmvu/GQPSYhZdNGoUSPs2rUL27Ztg7e3N2bOnIlFixYhMDBQ0+bzzz/HyJEjMWzYMDRq1AgpKSk4dOiQ1nD/li1b4OnpiXfeeQedOnVCixYttJ6xYG9vj8OHDyMmJga+vr747LPPMHXqVL3eUgkUYQ7Dw4cPUa1atRzr1Wq1VndIYXTp0kXr89dff40VK1bg7NmzqF27tq7RdDZ6wLt4npqGpr1nwUypQJZawJefvIdeHRoV+7n17WlSCrKy1CjnYKu1vpyDHW7ejc9jL+kxt+HJNTtzG5Zccxub9957D++9916e2xUKBb766it89dVXebZxcHDA1q1b8z1PnTp1cPLkySLnLAydC4ZatWrh5MmTmjGYbD///DPq169f5CBZWVn46aefkJqaqhm7+bf09HSkp6drPv/71hZd7f7tD/x86AJWfxUEzyoVcOXGA3y58Bc4l3s9+ZGIiN4e+rpLwlTpXDBMnToVQUFBePjwIdRqNXbu3Ino6Ghs3LgR+/bt0znAlStX4Ofnh7S0NNjY2GDXrl05ZpVmCw0NxYwZM3Q+R16mLd2NUQPeRY/2vgCAWtVcEBuXiEUbDsuuYHAsbQMzM2WOyUiPE1Uo72iXx17SY27Dk2t25jYsuebOj+L/i5j9TZnOcxi6deuGvXv34rfffkOpUqUwdepUXLt2DXv37sW7776rc4CaNWsiKioK586dw/DhwxEUFIS//vor17aTJk1CcnKyZomNjdX5fG96mZYB5b/eJmKmVEJQC6KOKwWLEuao5+mGsIh/ZuSq1WqciLiBRj4e+ewpLeY2PLlmZ27Dkmvu/Bh60uPbpkjPYWjZsiWOHDmilwAWFhaaORG+vr6IiIjA4sWLsWrVqhxt83qaVlEFtPTGgnWHUdGpDDyrVMDlGw+wYtvv+KhLU02bZ8mpeBD/DHGPkwEAt+69Hrsr72gHJyOrskd81A4jZmxCfa9KaFC7MlZs+x2pL9MR+Mb3MUbMbXhyzc7chiXX3FQ8ivzgpgsXLuDatWsAXs9r8PX11UsgtVqtNU+hOH3zWS+ErtqP8fN24MmzFDiXtUfQ+80xfnAHTZuDJ69g5Mwtms9DJq8HAHw+pCMmDO1kkJyF1aO9L54kpWD2qv1IePocPjVc8fOSYKPvPmRuw5NrduY2LLnmzktRX1H95v6mTCEIgk797w8ePEDfvn1x+vRplC5dGgCQlJSEZs2a4ccff0TFioV/CuKkSZPQsWNHVKpUCc+fP8fWrVsxZ84c/Prrr4Ua3lCpVLC3t8ffj5O0nrolB/8eCiEiMkUqlQpOjvZITk4utj/Hs39X9F59CiWsbYp8nMyXKdgxrEWxZjVmOs9hGDJkCDIzM3Ht2jUkJiYiMTER165dg1qtxpAhQ3Q6VkJCAgYMGICaNWvinXfeQURERKGLBSIiIjIcnYckwsLCcObMGdSs+c/DPGrWrImlS5eiZcuWOh1Lbo+SJiIieTPxeYui6FwwuLm55fqApqysLM1jKomIiIyN2DsdTP0uCZ2HJObNm4eRI0fiwoULmnUXLlzAqFGj8O233+o1HBERERmHQvUwlClTRquySk1NRZMmTWBu/nr3V69ewdzcHB9//LHmhRlERETGhHdJiFOogmHRokXFHIOIiKh4cUhCnEIVDEFBQcWdg4iIqFjx0dDiFPnBTQCQlpaGjIwMrXWmeG8qERHR207ngiE1NRUTJkzAjh078PTp0xzbs7Ky9BKMiIhIn/i2SnF0vkvi888/x7Fjx7BixQpYWlri+++/x4wZM+Di4oKNGzcWR0YiIiLRFArxiynTuYdh79692LhxI9q0aYNBgwahZcuWqFatGtzd3bFlyxYEBgYWR04iIiKSkM49DImJiahSpQqA1/MVEhMTAQAtWrTAiRMn9JuOiIhIT/h6a3F0LhiqVKmCmJgYAICnpyd27NgB4HXPQ/bLqIiIiIwNhyTE0blgGDRoEC5dugQAmDhxIpYtWwYrKyuMGTMG48eP13tAIiIikp7OcxjGjBmj+Xd/f39cv34dkZGRqFatGurUqaPXcERERPrCuyTEEfUcBgBwd3eHu7u7PrIQEREVG7HDCiZeLxSuYFiyZEmhD/jpp58WOQwREREZp0IVDAsXLizUwRQKBQsGIiIySnyXhDiFKhiy74owVpy9SkREBVGiCDP9/7W/KRM9h4GIiEgO2MMgjqkXTERERFQI7GEgIiKToFAASt4lUWQsGIiIyCQoRRYMYvZ9G3BIgoiIiApUpILh5MmT6NevH/z8/PDw4UMAwKZNm3Dq1Cm9hiMiItIXvnxKHJ0Lhl9++QUBAQGwtrbGH3/8gfT0dABAcnIyZs+erfeARERE+pA9JCFmMWU6FwyzZs3CypUrsWbNGpQoUUKzvnnz5rh48aJewxEREZFx0HnSY3R0NFq1apVjvb29PZKSkvSRiYiISO/4LglxdO5hcHZ2xq1bt3KsP3XqFKpUqaKXUERERPqW/bZKMYsp07lgGDp0KEaNGoVz585BoVDg0aNH2LJlC8aNG4fhw4cXR0YiIiKSmM5DEhMnToRarcY777yDFy9eoFWrVrC0tMS4ceMwcuTI4shIREQkGt8lIY7OBYNCocCXX36J8ePH49atW0hJSUGtWrVgY2NTHPmIiIj0gnMYxCnykx4tLCxQq1YtfWYhIiIqNkqIm4eghGlXDDoXDG3bts334RXHjh0TFYiIiIiMj84FQ7169bQ+Z2ZmIioqCn/++SeCgoL0lYuIiEivOCQhjs4Fw8KFC3NdP336dKSkpIgOZGiPEpIw47v/4rczf+FleiY8KpbFd1P6oX6tSgAAh8a5T+ScPrIbPu3vb8iohbJmRxiWbj6KhKcqeFd3xZzxveBbu7LUsQrE3IYn1+zMbVhyzZ0bvnxKHL1N+uzXrx/Wrl2rr8MZRJLqBToOXQhzczPsWDwc4T9+gZmj3kdpO2tNm2sHvtZalk4JhEKhQNd29aQLnoedhyMxedEuTBjSEcc3TYB3dVf0HLkMjxOfSx0tX8xteHLNztyGJdfcVDz0VjCEh4fDysqqyPt/8803UCgUGD16tL4iFWjxxiNwLV8ay6b2g2/tynB3LYt2Tb3gUbGcpo1TWTut5WDYZbT0rY7KrmUNlrOwlm89hgHdmyGwqx88q1TAgkl9UNLKApv3hEsdLV/MbXhyzc7chiXX3HlRKMQ9vIlDEjrq0aOH1mdBEPD333/jwoULmDJlSpFCREREYNWqVahTp06R9i+qgyf/RLsmnhg48Qec+eMWKpQrjY8/aIGg7s1zbZ/wVIXDp69i+bT+Bs1ZGBmZrxB1PRZjBrbXrFMqlWjduCYirsRImCx/zG14cs3O3IYl19z54RwGcXTuYbC3t9daHBwc0KZNGxw4cADTpk3TOUBKSgoCAwOxZs0alClTRuf9xbj38AnW7TyFqpXK4eclIzCoZwtMmv8Ltu07l2v7H/efh00pK7zXtq5BcxbG06QUZGWpUc7BVmt9OQc7JDxVSZSqYMxteHLNztyGJdfcVHx06mHIysrCoEGD4OPjo7df7sHBwejcuTP8/f0xa9asfNump6drXqcNACqVuB9atVpAPa9KmDKiKwCgTk03XL/9N9btPIW+7zXJ0X7L3nD0CmgIK8sSObYREZFx46RHcXTqYTAzM0P79u319lbKH3/8ERcvXkRoaGih2oeGhmr1bri5uYk6v1NZO9T0cNZaV6OyEx7GP8vRNvyPW7h5LwH9u/mJOmdxcSxtAzMzZY7JSI8TVSjvaCdRqoIxt+HJNTtzG5Zcc+dHoYd/TJnOQxLe3t64c+eO6BPHxsZi1KhR2LJlS6EnS06aNAnJycmaJTY2VlSGJnWq4Na9eK11t+4noKKzQ462m/eEo56nG7xrVBR1zuJiUcIc9TzdEBYRrVmnVqtxIuIGGvl4SJgsf8xteHLNztyGJdfcVHx0nvQ4a9YsjBs3DjNnzoSvry9KlSqltd3OrnCVZ2RkJBISEtCgQQPNuqysLJw4cQLfffcd0tPTYWZmprWPpaUlLC0tdY2cp+EftUWHwQuwYN2v6O7fABev3sPG3Wew8Is+Wu1UKS/x36NRmDnqfb2duziM+KgdRszYhPpeldCgdmWs2PY7Ul+mI7BLU6mj5Yu5DU+u2ZnbsOSaOy8ckhCn0AXDV199hc8++wydOnUCAHTt2lXrEdGCIEChUCArK6tQx3vnnXdw5coVrXWDBg2Cp6cnJkyYkKNYKA4Narlj09yh+Gr5Hsz74RAquTji67E90KtDI612O49chCAI6BngW+yZxOjR3hdPklIwe9V+JDx9Dp8arvh5SbDRdx8yt+HJNTtzG5Zcc+eFBYM4CkEQhMI0NDMzw99//41r167l265169ZFDtOmTRvUq1cPixYtKlR7lUoFe3t7xD1JKnTPhrHI730cRESmQqVSwcnRHsnJycX253j274qv9kXBqpRtwTvkIS31Oaa+V69YsxqzQvcwZNcVYgoCIiIikied5jAU99+Kjx8/XqzHJyIi08UhCXF0Khhq1KhRYNGQmJgoKhAREVFx4JMexdGpYJgxYwbs7e2LKwsREREZKZ0Khj59+qB8+fLFlYWIiKjYZL9ESsz+pqzQBQNn9RMRkZxxDoM4hX7SYyHvviQiIqK3UKF7GNRqdXHmICIiKl4iJz2a+KskdH80NBERkRwpoYBSxG99Mfu+DXR++RQRERHp5ptvvoFCocDo0aM169LS0hAcHAxHR0fY2NigZ8+eiI/XfiHi/fv30blzZ5QsWRLly5fH+PHj8erVK602x48fR4MGDWBpaYlq1aph/fr1xfIdWDAQEZFJyH4Og5ilKCIiIrBq1SrUqVNHa/2YMWOwd+9e/PTTTwgLC8OjR4/Qo0cPzfasrCx07twZGRkZOHPmDDZs2ID169dj6tSpmjYxMTHo3Lkz2rZti6ioKIwePRpDhgzBr7/+WrSw+WDBQEREJiH7Lgkxi65SUlIQGBiINWvWoEyZMpr1ycnJ+OGHH7BgwQK0a9cOvr6+WLduHc6cOYOzZ88CAA4fPoy//voLmzdvRr169dCxY0fMnDkTy5YtQ0ZGBgBg5cqV8PDwwPz58+Hl5YWQkBB88MEHWLhwoV6u2ZtYMBARkUnIfg6DmAV4/TKrN5f09PQ8zxkcHIzOnTvD399fa31kZCQyMzO11nt6eqJSpUoIDw8HAISHh8PHxwdOTk6aNgEBAVCpVLh69aqmzb+PHRAQoDmGPrFgICIi0oGbmxvs7e01S2hoaK7tfvzxR1y8eDHX7XFxcbCwsEDp0qW11js5OSEuLk7T5s1iIXt79rb82qhUKrx8+bJI3y8vvEuCiIhMgr7eJREbG6v1emtLS8scbWNjYzFq1CgcOXIEVlZWRT+pEWEPAxERmQQlRA5J/P+2Sjs7O60lt4IhMjISCQkJaNCgAczNzWFubo6wsDAsWbIE5ubmcHJyQkZGBpKSkrT2i4+Ph7OzMwDA2dk5x10T2Z8LamNnZwdra2u9XLdsLBiIiIj07J133sGVK1cQFRWlWRo2bIjAwEDNv5coUQJHjx7V7BMdHY379+/Dz88PAODn54crV64gISFB0+bIkSOws7NDrVq1NG3ePEZ2m+xj6BOHJIiIyCQY8vXWtra28Pb21lpXqlQpODo6atYPHjwYY8eOhYODA+zs7DBy5Ej4+fmhadOmAID27dujVq1a6N+/P+bOnYu4uDhMnjwZwcHBml6NTz75BN999x0+//xzfPzxxzh27Bh27NiB/fv3F/2L5uGtKBgUCgVfjmUgma/k+4jwEubsUCMyZUqI61bX958gCxcuhFKpRM+ePZGeno6AgAAsX75cs93MzAz79u3D8OHD4efnh1KlSiEoKAhfffWVpo2Hhwf279+PMWPGYPHixahYsSK+//57BAQE6DktoBBk/FYplUoFe3t7xD9N1pqAQsWHBQMR6ZNKpYKToz2Sk4vvz/Hs3xXLj/0JaxvbIh/nZcpzjGjnXaxZjdlb0cNARERUELG90abek82CgYiITIIC4l44adrlAu+SICIiokJgDwMREZmENx/vXNT9TRkLBiIiMhmm/StfHBYMRERkEgz5HIa3EecwEBERUYHYw0BERCaBt1WKw4KBiIhMgrE96VFuTP37ExERUSGwh4GIiEwChyTEYcFAREQmgU96FIdDEkRERFQg9jAQEZFJ4JCEOCwYiIjIJPAuCXFYMORhzY4wLN18FAlPVfCu7oo543vBt3ZlqWMVyJhyL95wGPvDLuPmvXhYW5ZAQx8PTB3RFdXcnbTaRVyJQeiqfbh49R6USgW8a1TE9oXDYW1lAQBYuP5XHDl9FVdvPkSJEua4dWSOFF8nV8Z0vXUl1+zMbVhyzU36Z+oFU652Ho7E5EW7MGFIRxzfNAHe1V3Rc+QyPE58LnW0fBlb7jN/3MLHPVvi4Jqx2LE4GK9eZaH36OVIfZmuaRNxJQZ9xqxAm8aeOPTDZzi8dhwG92wJpfKfrr+MzCx0bVcfQT1aSPE18mRs11sXcs3O3IYl19x5yR6SELOYMkkLhunTp+f4j+Hp6SllJADA8q3HMKB7MwR29YNnlQpYMKkPSlpZYPOecKmj5cvYcm9fNAJ9OjeBZ5UK8K7uiiWTA/Eg7hkuX4/VtJm6eCeG9mqNTwe8C88qFVDN3Qnd/BvA0qKEps2EoZ3wSd+2qFXVRYqvkSdju966kGt25jYsuebOi0IPiymTvIehdu3a+PvvvzXLqVOnJM2TkfkKUddj0aZxTc06pVKJ1o1rIuJKjITJ8ieH3KqUNABAabuSAIDHic8RefUeyjrYoNPQBajV6Ut0G74YZy/dljJmocjheudFrtmZ27Dkmjs/2S+fErOYMskLBnNzczg7O2uWsmXLSprnaVIKsrLUKOdgq7W+nIMdEp6qJEpVMGPPrVarMWXRTjSuUwVe/+8puPfoCQBg3vcH0b9bM2xf+Anq1HTDByO/w53YBCnjFsjYr3d+5JqduQ1Lrrmp+EheMNy8eRMuLi6oUqUKAgMDcf/+/TzbpqenQ6VSaS0kDxO+/QnX7/yN1TODNOvUagEAMKB7c/R9ryl8arph5ugeqFrJCVv3npUqKhG9pZRQiF5MmaQFQ5MmTbB+/XocOnQIK1asQExMDFq2bInnz3OfUBMaGgp7e3vN4ubmpvdMjqVtYGamzDGp53GiCuUd7fR+Pn0x5twTv/0JR05fxc5lI+FSvoxmvVNZewBADQ9nrfY1KjvhQfwzg2bUlTFf74LINTtzG5Zcc+eHQxLiSFowdOzYEb169UKdOnUQEBCAAwcOICkpCTt27Mi1/aRJk5CcnKxZYmNjc20nhkUJc9TzdENYRLRmnVqtxomIG2jk46H38+mLMeYWBAETv/0JB8IuY+d3IXB3cdTaXqmCA5zL2uP2Pe3hh9v3E+Dm7GDIqDozxutdWHLNztyGJdfcVHyM6jkMpUuXRo0aNXDr1q1ct1taWsLS0rLYc4z4qB1GzNiE+l6V0KB2ZazY9jtSX6YjsEvTYj+3GMaWe8K3P2Hn4UhsnDMEpUpaIf7/4552paxgbWUBhUKB4MB2mPv9QdSu7oLa1Stix4HzuHUvAT/M/lhznAdxiXimeoEHcYnIUqtx5cYDAIBHxXKwKVn8Pw95MbbrrQu5Zmduw5Jr7rwo/v+PmP1NmVEVDCkpKbh9+zb69+8vaY4e7X3xJCkFs1ftR8LT5/Cp4YqflwQbfTecseVev/P1HS/dg5dqrV8yORB9OjcBAPynT1ukZ7zClMW7kKR6gVrVXLBjyQh4VCynaT9nzQFsP3Be8/mdoLkAgF3LRqJ5g+rF/TXyZGzXWxdyzc7chiXX3HkRO6xg6kMSCkEQBKlOPm7cOHTp0gXu7u549OgRpk2bhqioKPz1118oV65cgfurVCrY29sj/mky7Ozk+QMsN5mv1FJHKLIS5pLP8SWif1GpVHBytEdycvH9OZ79u+Kns7dQ0sa24B3y8CLlOXo1rVasWY2ZpD0MDx48QN++ffH06VOUK1cOLVq0wNmzZwtVLBAREelCIfJOBw5JSOjHH3+U8vRERGRCOCQhDvtoiYiIqEBGNemRiIiouLCHQRwWDEREZBJ4W6U4LBiIiMgkKBWvFzH7mzLOYSAiIqICsYeBiIhMAockxGHBQEREJoGTHsXhkAQREREViD0MRERkEhQQN6xg4h0MLBiIiMg08C4JcTgkQURERAViDwMREZkE3iUhDgsGIiIyCbxLQhwOSRAREVGB2MNAREQmQQFxdzqYeAcDCwYiIjINSiigFDGuoDTxkoEFA+nE3My0/4chIvliD4M4nMNAREREBWIPAxERmQZ2MYjCgoGIiEwCn8MgDockiIiIqEDsYSAiItMg8sFNJt7BwIKBiIhMA6cwiMMhCSIiIioQexiIiMg0sItBFBYMRERkEniXhDgckiAiIqICsYeBiIhMAl9vLQ4LBiIiMgmcwiAOCwYiIjINrBhE4RwGIiIiKhB7GIiIyCTwLglxWDAQEZFJ4KRHcTgkQUREVAxCQ0PRqFEj2Nraonz58ujevTuio6O12qSlpSE4OBiOjo6wsbFBz549ER8fr9Xm/v376Ny5M0qWLIny5ctj/PjxePXqlVab48ePo0GDBrC0tES1atWwfv16vX8fFgx5WLMjDHW6ToVz89HwHzgPkVfvSh2pUIw99zerD8Ch8UitpUmvmZrt8U9U+GTaRnh2+AIVW32GNv3nYM+xKOkCF8DYr3d+5JqduQ1Lrrlzo9DDoouwsDAEBwfj7NmzOHLkCDIzM9G+fXukpqZq2owZMwZ79+7FTz/9hLCwMDx69Ag9evTQbM/KykLnzp2RkZGBM2fOYMOGDVi/fj2mTp2qaRMTE4POnTujbdu2iIqKwujRozFkyBD8+uuvul6ifEleMDx8+BD9+vWDo6MjrK2t4ePjgwsXLkiaaefhSExetAsThnTE8U0T4F3dFT1HLsPjxOeS5iqIXHJ7VqmAawe+1iwH1ozRbBs+YxNu3YvHlvnDcGrbJLzXpi4+/mItLkfHSpg4d3K53rmRa3bmNiy55s6TgSuGQ4cOYeDAgahduzbq1q2L9evX4/79+4iMjAQAJCcn44cffsCCBQvQrl07+Pr6Yt26dThz5gzOnj0LADh8+DD++usvbN68GfXq1UPHjh0xc+ZMLFu2DBkZGQCAlStXwsPDA/Pnz4eXlxdCQkLwwQcfYOHChaIu179JWjA8e/YMzZs3R4kSJXDw4EH89ddfmD9/PsqUKSNlLCzfegwDujdDYFc/eFapgAWT+qCklQU27wmXNFdB5JLb3EwJp7J2msWxtI1mW8TlOxjauzV8a1dGZdeyGDe4A+xtrBF1zfgKBrlc79zINTtzG5Zccxc3lUqltaSnpxdqv+TkZACAg4MDACAyMhKZmZnw9/fXtPH09ESlSpUQHv76GoeHh8PHxwdOTk6aNgEBAVCpVLh69aqmzZvHyG6TfQx9kbRgmDNnDtzc3LBu3To0btwYHh4eaN++PapWrSpZpozMV4i6Hos2jWtq1imVSrRuXBMRV2Iky1UQOeW+E/sYtTp9ifrdp2PYlA14EJeo2daoThXsOnIRz5JToVar8cvhSKRnvEIL3+oSJs5JTtf73+SanbkNS66586PQwz8A4ObmBnt7e80SGhpa4LnVajVGjx6N5s2bw9vbGwAQFxcHCwsLlC5dWqutk5MT4uLiNG3eLBayt2dvy6+NSqXCy5cvdb9QeZD0Lok9e/YgICAAvXr1QlhYGFxdXTFixAgMHTpUskxPk1KQlaVGOQdbrfXlHOxw8258HntJTy65fb3d8d3UfqjuXh5xT1SY+/1BdBq2CKe3fQHbUlZYN3sQPv5iHaq+OxHmZkpYW1lg49whqOJWTuroWuRyvXMj1+zMbVhyzZ0ffd0lERsbCzs7O816S0vLAvcNDg7Gn3/+iVOnThU9gMQk7WG4c+cOVqxYgerVq+PXX3/F8OHD8emnn2LDhg25tk9PT8/RFUTy8m6z2ujuXx+1q7viHT8v7Fj0CZKfv8Tu3/4AAMxeuR/JKS+x67sQHNswHiM+aouPv1iHv249kjg5EdFrdnZ2WktBBUNISAj27duH33//HRUrVtSsd3Z2RkZGBpKSkrTax8fHw9nZWdPm33dNZH8uqI2dnR2sra2L9B1zI2nBoFar0aBBA8yePRv169fHsGHDMHToUKxcuTLX9qGhoVrdQG5ubnrP5FjaBmZmyhyTeh4nqlDe0S6PvaQn19z2tiVRrVJ5xDx4jJgHj7HmpxNYOjkQrRvXhHeNipgwtBPqe7nh+59OSB1Vi1yvNyDf7MxtWHLNnR9D3yUhCAJCQkKwa9cuHDt2DB4eHlrbfX19UaJECRw9elSzLjo6Gvfv34efnx8AwM/PD1euXEFCQoKmzZEjR2BnZ4datWpp2rx5jOw22cfQF0kLhgoVKmi+cDYvLy/cv38/1/aTJk1CcnKyZomN1f9EOIsS5qjn6YawiH/ulVWr1TgRcQONfDzy2VNacs2d8iIdMQ+fwKmsHV6mZQIAlErt/y2VSiXUgiBFvDzJ9XoD8s3O3IYl19z5MnDFEBwcjM2bN2Pr1q2wtbVFXFwc4uLiNPMK7O3tMXjwYIwdOxa///47IiMjMWjQIPj5+aFp06YAgPbt26NWrVro378/Ll26hF9//RWTJ09GcHCwpmfjk08+wZ07d/D555/j+vXrWL58OXbs2IExY8bkma0oJJ3D0Lx58xwPsbhx4wbc3d1zbW9paVmosSKxRnzUDiNmbEJ9r0poULsyVmz7Hakv0xHYpWmxn1sMOeSesngXOrT0hpuzA/5+koxvVh+AmVKJnu19YW9bElXcymFs6I/4alR3ONiXwv6wyzh+Pho/LviP1NFzkMP1zotcszO3Yck1d14M/WjoFStWAADatGmjtX7dunUYOHAgAGDhwoVQKpXo2bMn0tPTERAQgOXLl2vampmZYd++fRg+fDj8/PxQqlQpBAUF4auvvtK08fDwwP79+zFmzBgsXrwYFStWxPfff4+AgICifdE8KARBur+6RUREoFmzZpgxYwZ69+6N8+fPY+jQoVi9ejUCAwML3F+lUsHe3h7xT5O1JqDow+odYVi66TckPH0Onxqu+GZcLzT0rqzXcxSH4s4t9sdl8JfrEP7HLSQmv4BjGRs0rVsFk4e/B4+Kryc13r6fgBnL9uDcpTtIfZEOj4plEdLvHXzYqbHo7IpieK6rXH9OAPlmZ27DKu7cKpUKTo72SE7W/5/jb57D3t4eZ689go1t0c+R8lyFpl4uxZrVmElaMADAvn37MGnSJNy8eRMeHh4YO3Zsoe+SKM6CgXIn8Y+LKMVRMBCROIYsGM5dF18wNPE03YJB8pdPvffee3jvvfekjkFERG+5okxc/Pf+pkzyR0MTERGR8ZO8h4GIiMgg2MUgCgsGIiIyCYa+S+JtwyEJIiIiKhB7GIiIyCTo610SpooFAxERmQROYRCHQxJERERUIPYwEBGRaWAXgygsGIiIyCTwLglxWDAQEZFpEDnp0cTrBc5hICIiooKxh4GIiEwCpzCIw4KBiIhMAysGUTgkQURERAViDwMREZkE3iUhDgsGIiIyCXw0tDgckiAiIqICsYeBdKIw9RKbiGSLcx7FYcFARESmgRWDKBySICIiogKxh4GIiEwC75IQhwUDERGZBAVE3iWhtyTyxIKBiIhMAqcwiMM5DERERFQg9jAQEZFJ4IObxGHBQEREJoKDEmJwSIKIiIgKxB4GIiIyCRySEIcFAxERmQQOSIjDIQkiIiIqEHsYiIjIJHBIQhwWDEREZBL4aGhxOCRBREREBWIPAxERmQbOehSFPQx5WLMjDHW6ToVz89HwHzgPkVfvSh2pUIw99+mLt9BnzEp4dfwCZRqFYP/xS1rbBUHA7JX74NnhC1RoMQbdRyzF7fsJEqUtmLFf7/zINTtzG5Zcc+dGoYfFlElaMFSuXBkKhSLHEhwcLGUs7DwcicmLdmHCkI44vmkCvKu7oufIZXic+FzSXAWRQ+4XL9PhXcMV8z7/MNftizf+hlXbw7BgUh8cWTcOJa0t0HPkMqSlZxo4acHkcL3zItfszG1Ycs2dl+xJj2IWUyZpwRAREYG///5bsxw5cgQA0KtXLyljYfnWYxjQvRkCu/rBs0oFLJjUByWtLLB5T7ikuQoih9zvNq+NycO74L22dXNsEwQBK7f9jnEfB6BT6zrwru6KFTMGIO5JMvaHXcrlaNKSw/XOi1yzM7dhyTU3FQ9JC4Zy5crB2dlZs+zbtw9Vq1ZF69atJcuUkfkKUddj0aZxTc06pVKJ1o1rIuJKjGS5CiLX3G+69/Ap4p+q0Kaxp2advY01fGtXRsTlu9IFy4Wcr7dcszO3Yck1d34UevjHlBnNHIaMjAxs3rwZH3/8MRQS9vs8TUpBVpYa5RxstdaXc7BDwlOVRKkKJtfcb4r/f85yjtrfobyjrdF9Bzlfb7lmZ27DkmvufHESgyhGc5fE7t27kZSUhIEDB+bZJj09Henp6ZrPKpVMf2iJiIhkxmh6GH744Qd07NgRLi4uebYJDQ2Fvb29ZnFzc9N7DsfSNjAzU+aY1PM4UYXyjnZ6P5++yDX3m5z+n/PxU+3vkPD0udF9Bzlfb7lmZ27Dkmvu/LCDQRyjKBju3buH3377DUOGDMm33aRJk5CcnKxZYmNj9Z7FooQ56nm6ISwiWrNOrVbjRMQNNPLx0Pv59EWuud/k7uoIJ0c7re+gSnmJyKt30ahOZemC5ULO11uu2ZnbsOSaOz+8S0IcoxiSWLduHcqXL4/OnTvn287S0hKWlpbFnmfER+0wYsYm1PeqhAa1K2PFtt+R+jIdgV2aFvu5xZBD7pQX6YiJfaz5fO/RU1yJfoDS9iXh5uyAT/q2xbdrD6GKWzm4uzpi9sr9cC5rj86tc95VITU5XO+8yDU7cxuWXHNT8ZC8YFCr1Vi3bh2CgoJgbi55HABAj/a+eJKUgtmr9iPh6XP41HDFz0uCjb4bTg65o67dQ5dPlmg+f7lwJwCgb+cmWD69P0YN8MeLl+kYM3sbklNeomndqvh5yQhYWZaQKnKe5HC98yLX7MxtWHLNnTexdzqYdheDQhAEQcoAhw8fRkBAAKKjo1GjRg2d9lWpVLC3t0f802TY2cn1B5iIyHSpVCo4OdojObn4/hzP/l1x9+9EUedQqVSoXMGhWLMaM8n/St++fXtIXLMQERFRAYxi0iMREREZN8l7GIiIiAxB7J0OvEuCiIjIBIh9vDMfDU1ERERUAPYwEBGRSeCQhDgsGIiIyCSIfbyzidcLHJIgIiKigrGHgYiITAO7GERhwUBERCaBd0mIwyEJIiIiKhB7GIiIyCTwLglxWDAQEZFJ4BQGcTgkQUREVIyWLVuGypUrw8rKCk2aNMH58+eljlQkLBiIiMg0KPSw6Gj79u0YO3Yspk2bhosXL6Ju3boICAhAQkKC+O9jYCwYiIjIJCj08I+uFixYgKFDh2LQoEGoVasWVq5ciZIlS2Lt2rXF8A2LFwsGIiIyCdmTHsUsusjIyEBkZCT8/f0165RKJfz9/REeHq7nb1f8ZD3pURAEAMBzlUriJEREVBTZf35n/3lenFQif1dk7//v41haWsLS0jJH+ydPniArKwtOTk5a652cnHD9+nVRWaQg64Lh+fPnAIBqHm4SJyEiIjGeP38Oe3v7Yjm2hYUFnJ2dUV0PvytsbGzg5qZ9nGnTpmH69Omij23sZF0wuLi4IDY2Fra2tlDo+QZZlUoFNzc3xMbGws7OTq/HLk5yzQ3INztzGxZzG15xZhcEAc+fP4eLi4tej/smKysrxMTEICMjQ/SxBEHI8fsmt94FAChbtizMzMwQHx+vtT4+Ph7Ozs6isxiarAsGpVKJihUrFus57OzsZPc/NyDf3IB8szO3YTG34RVX9uLqWXiTlZUVrKysiv08b7KwsICvry+OHj2K7t27AwDUajWOHj2KkJAQg2bRB1kXDERERMZs7NixCAoKQsOGDdG4cWMsWrQIqampGDRokNTRdMaCgYiIqJh8+OGHePz4MaZOnYq4uDjUq1cPhw4dyjERUg5YMOTB0tIS06ZNy3NsyljJNTcg3+zMbVjMbXhyzm4MQkJCZDkE8W8KwRD3shAREZGs8cFNREREVCAWDERERFQgFgxERERUIBYMRCaMU5iIqLB4l8T/PXnyBGvXrkV4eDji4uIAAM7OzmjWrBkGDhyIcuXKSZyQSP8sLS1x6dIleHl5SR2FiIwc75IAEBERgYCAAJQsWRL+/v6a+2Pj4+Nx9OhRvHjxAr/++isaNmwocdK3y8uXLxEZGQkHBwfUqlVLa1taWhp27NiBAQMGSJQub9euXcPZs2fh5+cHT09PXL9+HYsXL0Z6ejr69euHdu3aSR0xh7Fjx+a6fvHixejXrx8cHR0BvH4VrzFLTU3Fjh07cOvWLVSoUAF9+/bVZCf9GDlyJHr37o2WLVtKHYWMjUBCkyZNhGHDhglqtTrHNrVaLQwbNkxo2rSpBMnEu3//vjBo0CCpY+QQHR0tuLu7CwqFQlAqlUKrVq2ER48eabbHxcUJSqVSwoS5O3jwoGBhYSE4ODgIVlZWwsGDB4Vy5coJ/v7+Qrt27QQzMzPh6NGjUsfMQaFQCPXq1RPatGmjtSgUCqFRo0ZCmzZthLZt20odMwcvLy/h6dOngiC8/lmuXLmyYG9vLzRq1EhwcHAQypcvL9y5c0filDlFRkZq5dq4caPQrFkzoWLFikLz5s2Fbdu2SZguf9n/T1avXl345ptvhL///lvqSGQkWDAIgmBlZSVcu3Ytz+3Xrl0TrKysDJhIf6KioozyF2/37t2Fzp07C48fPxZu3rwpdO7cWfDw8BDu3bsnCILxFgx+fn7Cl19+KQiCIGzbtk0oU6aM8MUXX2i2T5w4UXj33Xelipen0NBQwcPDI0cxY25uLly9elWiVAVTKBRCfHy8IAiCEBgYKDRr1kxISkoSBEEQnj9/Lvj7+wt9+/aVMmKu6tSpIxw5ckQQBEFYs2aNYG1tLXz66afCihUrhNGjRws2NjbCDz/8IHHK3CkUCuG3334TRo0aJZQtW1YoUaKE0LVrV2Hv3r1CVlaW1PFIQiwYBEGoXLmysGHDhjy3b9iwQXB3dzdcIB3897//zXdZuHChUf7iLV++vHD58mXNZ7VaLXzyySdCpUqVhNu3bxttwWBnZyfcvHlTEARByMrKEszNzYWLFy9qtl+5ckVwcnKSKl6+zp8/L9SoUUP47LPPhIyMDEEQ5FUwVKlSRTh8+LDW9tOnTwtubm5SRMuXtbW1cPfuXUEQBKF+/frC6tWrtbZv2bJFqFWrlhTRCvTmNc/IyBC2b98uBAQECGZmZoKLi4vwxRdfaP4fINPCSY8Axo0bh2HDhiEyMhLvvPNOjjkMa9aswbfffitxytx1794dCoUi39nu+n71tz68fPkS5ub//PgpFAqsWLECISEhaN26NbZu3SphuvxlX0+lUgkrKyutN+3Z2toiOTlZqmj5atSoESIjIxEcHIyGDRtiy5YtRvmz8W/ZGdPS0lChQgWtba6urnj8+LEUsfJVsmRJPHnyBO7u7nj48CEaN26stb1JkyaIiYmRKF3hlShRAr1790bv3r1x//59rF27FuvXr8c333yDrKwsqeORoUldsRiLH3/8UWjSpIlgbm4uKBQKQaFQCObm5kKTJk2E7du3Sx0vTy4uLsLu3bvz3P7HH38Y5d/UGzVqJGzcuDHXbcHBwULp0qWNMnedOnWEgwcPaj5fuXJFyMzM1Hw+ceKE4OHhIUU0nWzbtk1wcnISlEql0fcw+Pj4CPXr1xdsbGyEn3/+WWt7WFiY4OrqKlG6vPXr108YPHiwIAiC0KtXL2Hy5Mla22fPni34+PhIEa1Ab/Yw5EatVufo6SHTwB6G//vwww/x4YcfIjMzE0+ePAEAlC1bFiVKlJA4Wf58fX0RGRmJbt265bq9oN4Hqbz//vvYtm0b+vfvn2Pbd999B7VajZUrV0qQLH/Dhw/X+puVt7e31vaDBw8a5V0S/9anTx+0aNECkZGRcHd3lzpOnqZNm6b12cbGRuvz3r17jXI2/5w5c9C8eXO0bt0aDRs2xPz583H8+HF4eXkhOjoaZ8+exa5du6SOmSt3d3eYmZnluV2hUODdd981YCIyFrytUuZOnjyJ1NRUdOjQIdftqampuHDhAlq3bm3gZESmLSkpCd988w327t2LO3fuQK1Wo0KFCmjevDnGjBnD27RJdlgwEBERUYH4aGgiIiIqEAsGIiIiKhALBiIiIioQCwYikQYOHIju3btrPrdp0wajR482eI7jx49DoVAgKSkpzzYKhQK7d+8u9DGnT5+OevXqicp19+5dKBQKREVFiToOEUmLBQO9lQYOHAiFQgGFQgELCwtUq1YNX331FV69elXs5965cydmzpxZqLaF+SVPRGQM+BwGemt16NAB69atQ3p6Og4cOIDg4GCUKFECkyZNytE2IyMDFhYWejmvg4ODXo5DRGRM2MNAby1LS0s4OzvD3d0dw4cPh7+/P/bs2QPgn2GEr7/+Gi4uLqhZsyYAIDY2Fr1790bp0qXh4OCAbt264e7du5pjZmVlYezYsShdujQcHR3x+eef53gw1r+HJNLT0zFhwgS4ubnB0tIS1apVww8//IC7d++ibdu2AIAyZcpAoVBg4MCBAAC1Wo3Q0FB4eHjA2toadevWxc8//6x1ngMHDqBGjRqwtrZG27ZttXIW1oQJE1CjRg2ULFkSVapUwZQpU5CZmZmj3apVq+Dm5oaSJUuid+/eOR5//f3338PLywtWVlbw9PTE8uXLdc5CRMaNBQOZDGtra2RkZGg+Hz16FNHR0Thy5Aj27duHzMxMBAQEwNbWFidPnsTp06dhY2ODDh06aPabP38+1q9fj7Vr1+LUqVNITEws8Il9AwYMwLZt27BkyRJcu3YNq1atgo2NDdzc3PDLL78AAKKjo/H3339j8eLFAIDQ0FBs3LgRK1euxNWrVzFmzBj069cPYWFhAF4XNj169ECXLl0QFRWFIUOGYOLEiTpfE1tbW6xfvx5//fUXFi9ejDVr1mDhwoVabW7duoUdO3Zg7969OHToEP744w+MGDFCs33Lli2YOnUqvv76a1y7dg2zZ8/GlClTsGHDBp3zEJERk/K51ETFJSgoSOjWrZsgCK+ffX/kyBHB0tJSGDdunGa7k5OTkJ6ertln06ZNQs2aNQW1Wq1Zl56eLlhbWwu//vqrIAiCUKFCBWHu3Lma7ZmZmULFihU15xIEQWjdurUwatQoQRAEITo6WgCgedXxv/3+++8CAOHZs2eadWlpaULJkiWFM2fOaLUdPHiw5lXOkyZNyvG2wwkTJuQ41r8BEHbt2pXn9nnz5gm+vr6az9OmTRPMzMyEBw8eaNYdPHhQUCqVwt9//y0IgiBUrVpV2Lp1q9ZxZs6cKfj5+QmCIAgxMTECAOGPP/7I87xEZPw4h4HeWvv27YONjQ0yMzOhVqvx0UcfYfr06ZrtPj4+WvMWLl26hFu3bsHW1lbrOGlpabh9+zaSk5Px999/o0mTJppt5ubmaNiwYZ7v64iKioKZmZlOj+a+desWXrx4keN5/RkZGahfvz4A4Nq1a1o5AMDPz6/Q58i2fft2LFmyBLdv30ZKSgpevXoFOzs7rTaVKlWCq6ur1nnUajWio6Nha2uL27dvY/DgwRg6dKimzatXr7Te4klE8seCgd5abdu2xYoVK2BhYQEXFxet12kDQKlSpbQ+p6SkwNfXF1u2bMlxrHLlyhUpg7W1tc77pKSkAAD279+v9YsaeD0vQ1/Cw8MRGBiIGTNmICAgAPb29vjxxx8xf/58nbOuWbMmRwGT3wuMiEh+WDDQW6tUqVKoVq1aods3aNAA27dvR/ny5XP8LTtbhQoVcO7cObRq1QrA679JR0ZGokGDBrm29/HxgVqtRlhYGPz9/XNsz+7hePMNmLVq1YKlpSXu37+fZ8+El5eXZgJntrNnzxb8Jd9w5swZuLu748svv9Ssu3fvXo529+/fx6NHj+Di4qI5j1KpRM2aNeHk5AQXFxfcuXMHgYGBOp2fiOSFkx6J/i8wMBBly5ZFt27dcPLkScTExOD48eP49NNP8eDBAwDAqFGj8M0332D37t24fv06RowYke8zFCpXroygoCB8/PHH2L17t+aYO3bsAPD6VcIKhQL79u3D48ePkZKSAltbW4wbNw5jxozBhg0bcPv2bVy8eBFLly7VTCT85JNPcPPmTYwfPx7R0dHYunUr1q9fr9P3rV69Ou7fv48ff/wRt2/fxpIlS3KdwGllZYWgoCBcunQJJ0+exKefforevXvD2dkZADBjxgyEhoZiyZIluHHjBq5cuYJ169ZhwYIFOuUhIuPGgoHo/0qWLIkTJ06gUqVK6NGjB7y8vDB48GCkpaVpehw+++wz9O/fH0FBQfDz84OtrS3ef//9fI+7YsUKfPDBBxgxYgQ8PT0xdOhQpKamAgBcXV0xY8YMTJw4EU5OTggJCQEAzJw5E1OmTEFoaCi8vLzQoUMH7N+/Hx4eHgBezyv45ZdfsHv3btStWxcrV67E7Nmzdfq+Xbt2xZgxYxASEoJ69erhzJkzmDJlSo521apVQ48ePdCpUye0b98ederU0bptcsiQIfj++++xbt06+Pj4oHXr1li/fr0mKxG9Hfh6ayIiIioQexiIiIioQCwYiIiIqEAsGIiIiKhALBiIiIioQCwYiIiIqEAsGIiIiKhALBiIiIioQCwYiIiIqEAsGIiIiKhALBiIiIioQCwYiIiIqEAsGIiIiKhA/wP1tXcjSoCpOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 0.2091, Train Accuracy: 0.9464\n",
      "Validation Loss: 0.1670, Validation Accuracy: 0.9567\n",
      "{'accuracy': 0.9567092100724388, 'overall_precision': 0.2097327974897613, 'overall_recall': 0.24899000367170987, 'overall_f1': 0.22599614104972499}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 357/1691 [01:11<04:27,  4.99it/s, accuracy=0.955, loss=0.0112] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m total_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     11\u001b[0m     \n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Train for each epoch\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Evaluate on the validation set for each epoch\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     val_loss, val_acc, val_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_loader, device, label_encoder,(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),model_name)\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1668\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1682\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:409\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(current_states))\n\u001b[1;32m--> 409\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n\u001b[0;32m    411\u001b[0m         key_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Variables to store overall metrics across all epochs\n",
    "total_val_loss = 0\n",
    "total_val_acc = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train for each epoch\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate on the validation set for each epoch\n",
    "    val_loss, val_acc, val_metrics = evaluate_model(model, val_loader, device, label_encoder,(epoch+1),model_name)\n",
    "    \n",
    "    # Print per-epoch results\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(val_metrics)\n",
    "    \n",
    "    # Accumulate validation metrics across all epochs for later averaging\n",
    "    total_val_loss += val_loss\n",
    "    total_val_acc += val_acc\n",
    "    total_precision += val_metrics['overall_precision']\n",
    "    total_recall += val_metrics['overall_recall']\n",
    "    total_f1 += val_metrics['overall_f1']\n",
    "\n",
    "# Calculate and print overall mean metrics\n",
    "mean_val_loss = total_val_loss / epochs\n",
    "mean_val_acc = total_val_acc / epochs\n",
    "mean_precision = total_precision / epochs\n",
    "mean_recall = total_recall / epochs\n",
    "mean_f1 = total_f1 / epochs\n",
    "\n",
    "print(\"\\nOverall Validation Results:\")\n",
    "print(f\"Mean Validation Loss: {mean_val_loss:.4f}\")\n",
    "print(f\"Mean Validation Accuracy: {mean_val_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "print(f\"Mean F1 Score: {mean_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1691/1691 [05:31<00:00,  5.11it/s, accuracy=0.946, loss=0.0131]\n",
      "Evaluating: 100%|██████████| 725/725 [00:56<00:00, 12.87it/s, accuracy=0.957, loss=0.0104]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "Train Loss: 0.2091, Train Accuracy: 0.9464\n",
      "Validation Loss: 0.1670, Validation Accuracy: 0.9567\n",
      "{'accuracy': 0.9567092100724388, 'overall_precision': 0.2097327974897613, 'overall_recall': 0.24899000367170987, 'overall_f1': 0.22599614104972499}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  21%|██        | 357/1691 [01:11<04:27,  4.99it/s, accuracy=0.955, loss=0.0112] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n",
      "\u001b[0;32m      8\u001b[0m total_f1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n",
      "\u001b[0;32m     11\u001b[0m     \n",
      "\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Train for each epoch\u001b[39;00m\n",
      "\u001b[1;32m---> 13\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Evaluate on the validation set for each epoch\u001b[39;00m\n",
      "\u001b[0;32m     16\u001b[0m     val_loss, val_acc, val_metrics \u001b[38;5;241m=\u001b[39m evaluate_model(model, val_loader, device, label_encoder,(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m),model_name)\n",
      "\n",
      "Cell \u001b[1;32mIn[27], line 16\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, optimizer, device)\u001b[0m\n",
      "\u001b[0;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n",
      "\u001b[1;32m---> 16\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     17\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n",
      "\u001b[0;32m     18\u001b[0m logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1668\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[0;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n",
      "\u001b[0;32m   1662\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n",
      "\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n",
      "\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n",
      "\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n",
      "\u001b[0;32m   1666\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n",
      "\u001b[1;32m-> 1668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1680\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;32m   1682\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n",
      "\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n",
      "\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n",
      "\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n",
      "\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n",
      "\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n",
      "\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n",
      "\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n",
      "\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n",
      "\u001b[0;32m    686\u001b[0m         hidden_states,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    692\u001b[0m         output_attentions,\n",
      "\u001b[0;32m    693\u001b[0m     )\n",
      "\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n",
      "\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n",
      "\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n",
      "\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n",
      "\u001b[0;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n",
      "\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n",
      "\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n",
      "\u001b[0;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n",
      "\u001b[0;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n",
      "\u001b[1;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n",
      "\u001b[0;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:409\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n",
      "\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    408\u001b[0m     key_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey(current_states))\n",
      "\u001b[1;32m--> 409\u001b[0m     value_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranspose_for_scores(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_states\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention:\n",
      "\u001b[0;32m    411\u001b[0m         key_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([past_key_value[\u001b[38;5;241m0\u001b[39m], key_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n",
      "\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n",
      "\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n",
      "\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\ahmed\\miniconda3\\envs\\tf\\lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n",
      "\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n",
      "\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "\n",
    "# Variables to store overall metrics across all epochs\n",
    "total_val_loss = 0\n",
    "total_val_acc = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "total_f1 = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Train for each epoch\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate on the validation set for each epoch\n",
    "    val_loss, val_acc, val_metrics = evaluate_model(model, val_loader, device, label_encoder,(epoch+1),model_name)\n",
    "    \n",
    "    # Print per-epoch results\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(val_metrics)\n",
    "    \n",
    "    # Accumulate validation metrics across all epochs for later averaging\n",
    "    total_val_loss += val_loss\n",
    "    total_val_acc += val_acc\n",
    "    total_precision += val_metrics['overall_precision']\n",
    "    total_recall += val_metrics['overall_recall']\n",
    "    total_f1 += val_metrics['overall_f1']\n",
    "\n",
    "# Calculate and print overall mean metrics\n",
    "mean_val_loss = total_val_loss / epochs\n",
    "mean_val_acc = total_val_acc / epochs\n",
    "mean_precision = total_precision / epochs\n",
    "mean_recall = total_recall / epochs\n",
    "mean_f1 = total_f1 / epochs\n",
    "\n",
    "print(\"\\nOverall Validation Results:\")\n",
    "print(f\"Mean Validation Loss: {mean_val_loss:.4f}\")\n",
    "print(f\"Mean Validation Accuracy: {mean_val_acc:.4f}\")\n",
    "print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "print(f\"Mean F1 Score: {mean_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
