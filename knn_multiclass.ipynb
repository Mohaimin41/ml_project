{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T13:08:45.437857Z",
     "iopub.status.busy": "2024-11-14T13:08:45.437325Z",
     "iopub.status.idle": "2024-11-14T13:08:49.314877Z",
     "shell.execute_reply": "2024-11-14T13:08:49.313237Z",
     "shell.execute_reply.started": "2024-11-14T13:08:45.437797Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix\n",
    "# from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.tree import plot_tree\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "input_files = []\n",
    "\n",
    "for dirname, _, filenames in os.walk('dataset\\downsampled'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        input_files.append(os.path.join(dirname, filename))\n",
    "        \n",
    "print(input_files)\n",
    "print(\"\\nImports done\")\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup for CSECICIDS2018_improved and CICIDS2017_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T13:08:49.318059Z",
     "iopub.status.busy": "2024-11-14T13:08:49.317437Z",
     "iopub.status.idle": "2024-11-14T13:08:49.332555Z",
     "shell.execute_reply": "2024-11-14T13:08:49.331053Z",
     "shell.execute_reply.started": "2024-11-14T13:08:49.318011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def label_mapper(label):\n",
    "    # BENIGN, web_attack, ddos, botnet, infiltration, dos, ssh_bruteforce, ftp_bruteforce, others\n",
    "    if label == 'BENIGN':\n",
    "        return 0\n",
    "    elif label.startswith(\"Web Attack\"):\n",
    "        return 1\n",
    "    elif label.startswith(\"DDoS\"):\n",
    "        return 2\n",
    "    elif label.startswith(\"Botnet\"):\n",
    "        return 3\n",
    "    elif label.startswith(\"Infiltration\") or label.startswith(\"Portscan\") :\n",
    "        return 4\n",
    "    elif label.startswith(\"DoS\"):\n",
    "        return 5\n",
    "    elif label.startswith(\"SSH\"):\n",
    "        return 6\n",
    "    elif label.startswith(\"FTP\"):\n",
    "        return 7\n",
    "    else:\n",
    "        return 8\n",
    "\n",
    "\n",
    "def dataset_cleaner(df):\n",
    "    # change label\n",
    "    df['Label'] = df['Label'].apply(label_mapper)\n",
    "    \n",
    "    # drop all categorical columns\n",
    "    categorical_columns = df.select_dtypes(include=['object'])\n",
    "    df.drop(columns=categorical_columns.columns.values, inplace=True)\n",
    "    # id is unique for all, CISIAS notebook removed attempted category too\n",
    "    df.drop(columns=['id', 'Attempted Category'], inplace=True)\n",
    "    \n",
    "#     print(df.columns.values)\n",
    "    \n",
    "    # drop all inf and other nan values\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df.dropna(axis=0,how='any', inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_target_features(df, test_size = 0.30):\n",
    "    X = df.drop(['Label'], axis=1)\n",
    "    y = df['Label']\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "print(\"Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "def select_features_correlation(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Select top k features based on correlation with the target.\n",
    "\n",
    "    Parameters:\n",
    "    - X: DataFrame, the feature matrix.\n",
    "    - y: Series, the target variable.\n",
    "    - k: int, number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features based on correlation.\n",
    "    \"\"\"\n",
    "    # Factorize the target and convert to pandas Series\n",
    "    y_factorized = pd.Series(y.factorize()[0], index=y.index)\n",
    "    \n",
    "    # Convert categorical features to numeric\n",
    "    X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation = X_encoded.corrwith(y_factorized)\n",
    "    \n",
    "    # Create a DataFrame for correlation values\n",
    "    correlation_df = pd.DataFrame({\n",
    "        'Feature': correlation.index,\n",
    "        'Correlation': correlation.values\n",
    "    }).sort_values(by='Correlation', key=abs, ascending=False)\n",
    "    \n",
    "    # Select top k features\n",
    "    return correlation_df.head(k)['Feature'].tolist()\n",
    "\n",
    "def select_features_information_gain(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Select top k features based on information gain with the target.\n",
    "\n",
    "    Parameters:\n",
    "    - X: DataFrame, the feature matrix.\n",
    "    - y: Series, the target variable.\n",
    "    - k: int, number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features based on information gain.\n",
    "    \"\"\"\n",
    "    # Convert categorical features to numeric\n",
    "    X_encoded = X.apply(LabelEncoder().fit_transform)\n",
    "    \n",
    "    # Calculate information gain\n",
    "    info_gain = mutual_info_classif(X_encoded, y, discrete_features='auto', random_state=42)\n",
    "    \n",
    "    # Create a DataFrame for information gain values\n",
    "    info_gain_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Information Gain': info_gain\n",
    "    }).sort_values(by='Information Gain', ascending=False)\n",
    "    \n",
    "    # Select top k features\n",
    "    return info_gain_df.head(k)['Feature'].tolist()\n",
    "\n",
    "def get_top_features_across_files(file_paths, label_column, k=10):\n",
    "    \"\"\"\n",
    "    Get top k features across multiple files, based on both correlation and information gain.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths: list of file paths.\n",
    "    - label_column: name of the label column.\n",
    "    - k: number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - List of top k features consistent across all files.\n",
    "    \"\"\"\n",
    "    feature_counter = Counter()\n",
    "    idx = 1\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        X = df.drop(columns=[label_column])\n",
    "        y = df[label_column]\n",
    "        \n",
    "        # Select top features using both methods\n",
    "        top_corr_features = select_features_correlation(X, y, k)\n",
    "        top_ig_features = select_features_information_gain(X, y, k)\n",
    "        \n",
    "        # Combine and count features\n",
    "        feature_counter.update(top_corr_features + top_ig_features)\n",
    "        print(\"File \"+str(idx)+\" done.\")\n",
    "        idx = idx+1\n",
    "    \n",
    "    # Get most common features across files\n",
    "    most_common_features = feature_counter.most_common(k)\n",
    "    return [feature for feature, _ in most_common_features]\n",
    "\n",
    "def remove_selected_features(df, selected_features):\n",
    "    \"\"\"\n",
    "    Remove selected features from the given DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame, the input DataFrame.\n",
    "    - selected_features: list of feature names to be removed.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with the selected features removed.\n",
    "    \"\"\"\n",
    "    # Drop the selected features\n",
    "    updated_df = df.drop(columns=selected_features, errors='ignore')\n",
    "    return updated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = get_top_features_across_files(input_files,'Label',20)\n",
    "print(top_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load each file, do label clean up, run KNN on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T13:08:49.335342Z",
     "iopub.status.busy": "2024-11-14T13:08:49.334885Z",
     "iopub.status.idle": "2024-11-14T14:02:29.148390Z",
     "shell.execute_reply": "2024-11-14T14:02:29.146241Z",
     "shell.execute_reply.started": "2024-11-14T13:08:49.335296Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# we will add to these 3 lists test set and predictions for all csv\n",
    "# then we will merge them in one pandas object\n",
    "# then we can do metrics on the dataset as a whole\n",
    "# pros: will get whole dataset metrics\n",
    "# cons: the 3 list and merged object may overflow 30 gb ram (praying it wont)\n",
    "X_test_sets = []\n",
    "y_test_sets = []\n",
    "\n",
    "# MODELS\n",
    "print(\"Initializing KNN model\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for f in input_files:\n",
    "    \n",
    "    i += 1\n",
    "        \n",
    "    print(f\"{i}/{len(input_files)} CURRENT FILE: {f}\\n\")\n",
    "    \n",
    "    df = pd.read_csv(f)\n",
    "    \n",
    "    print(f\"LOADED FILE {f}, STARTING CLEANUP\\n\")\n",
    "    \n",
    "    df = dataset_cleaner(df)\n",
    "\n",
    "    \n",
    "    df = remove_selected_features(df,top_features)\n",
    "    \n",
    "    print(f\"CLEANUP DONE, STARTING SPLIT\\n\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_target_features(df, 0.30)\n",
    "    \n",
    "    # no need for df now\n",
    "    df = None\n",
    "    gc.collect()\n",
    "    \n",
    "    X_test.to_csv(f\"test_chunks/{i}X_test.csv\", index=False)\n",
    "    y_test.to_csv(f\"test_chunks/{i}y_test.csv\", index=False)\n",
    "    \n",
    "    # no need for the test sets either\n",
    "    del X_test\n",
    "    del y_test\n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"DONE WRITING TEST SETS TO FILES, STARTING TRAIN\\n\")\n",
    "    \n",
    "    # KNN\n",
    "    print(\"RUNNING KNN MODEL TRAIN...\\n\")\n",
    "    \n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    del X_train\n",
    "    del y_train\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"KNN MODEL TRAINED ON FILE: {f} \\n\\n\")\n",
    "    \n",
    "\n",
    "print(f\"{i}/{len(input_files)} files worked on\\n\\n\")\n",
    "\n",
    "# clear memory\n",
    "df = None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and prepare outputs for metric calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-14T15:13:31.460024Z",
     "iopub.status.busy": "2024-11-14T15:13:31.459486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"READING X TEST SETS AND PREDICTING\\n\")\n",
    "gc.collect()\n",
    "\n",
    "knn_predictions = []\n",
    "y_tests = []\n",
    "\n",
    "for curr in range(1,i+1):\n",
    "    print(f\"Reading X_test file {curr}/{i}\\n\")\n",
    "\n",
    "    df_X = pd.read_csv(f\"test_chunks/{curr}X_test.csv\")\n",
    "    \n",
    "    print(f\"Read {curr}-th X_test file, shape: {df_X.shape}\\nPredicting and appending...\")\n",
    "    \n",
    "    pred = knn_model.predict(df_X)\n",
    "    knn_predictions.append(pred)\n",
    "    \n",
    "    del df_X \n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"Done reading and predictiong on X_test file {curr}/{i}\\n\")\n",
    "    \n",
    "\n",
    "knn_predictions_joined = np.concatenate(knn_predictions)\n",
    "\n",
    "# remove prediction list\n",
    "del knn_predictions\n",
    "gc.collect()\n",
    "\n",
    "print(\"PREDICTION DONE USING KNN MODELS: \")\n",
    "print( knn_predictions_joined.shape)\n",
    "\n",
    "print(\"\\nREADING y_test FILES\\n\")\n",
    "\n",
    "for curr in range(1,i+1):\n",
    "    print(f\"Reading y_test file {curr}/{i}\\n\")\n",
    "\n",
    "    df_y = pd.read_csv(f\"test_chunks/{curr}y_test.csv\")\n",
    "    \n",
    "    print(f\"Read {curr}-th y_test file, shape: {df_y.shape}\\nAppending...\")\n",
    "    \n",
    "    y_tests.append(df_y)\n",
    "    \n",
    "    del df_y\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"Done reading and adding y_test file {curr}/{i}\\n\")\n",
    "    \n",
    "y_test_sets_joined = pd.concat(y_tests)\n",
    "\n",
    "# remove y_tests\n",
    "del y_tests\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "print(\"DONE READING y_test FILES: \")\n",
    "print(y_test_sets_joined.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-14T14:02:29.172962Z",
     "iopub.status.idle": "2024-11-14T14:02:29.173578Z",
     "shell.execute_reply": "2024-11-14T14:02:29.173290Z",
     "shell.execute_reply.started": "2024-11-14T14:02:29.173248Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "knn_accuracy = accuracy_score(y_test_sets_joined, knn_predictions_joined)\n",
    "knn_f1 = f1_score(y_test_sets_joined, knn_predictions_joined, average='macro')\n",
    "knn_precision = precision_score(y_test_sets_joined, knn_predictions_joined, average='macro')\n",
    "knn_recall = recall_score(y_test_sets_joined, knn_predictions_joined, average='macro')\n",
    "\n",
    "print(\"KNN METRICS: \\n\")\n",
    "print(f\"ACCURACY: \\t {knn_accuracy:.4f}\")\n",
    "print(f\"F1 SCORE: \\t {knn_f1:.4f}\")\n",
    "print(f\"PRECISION: \\t {knn_precision:.4f}\")\n",
    "print(f\"RECALL: \\t {knn_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-14T14:02:29.176215Z",
     "iopub.status.idle": "2024-11-14T14:02:29.177023Z",
     "shell.execute_reply": "2024-11-14T14:02:29.176649Z",
     "shell.execute_reply.started": "2024-11-14T14:02:29.176612Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "classes = [\"BENIGN\", \"Web Attack\", \"DDoS\", \"Botnet\", \"Infiltration\", \"DoS\", \"SSH Bruteforce\", \"FTP Bruteforce\", \"Others\"]\n",
    "title = \"Confusion Matrix for KNN Classifier\"\n",
    "\n",
    "cm = confusion_matrix(y_test_sets_joined, knn_predictions_joined)\n",
    "plt.figure(figsize=(14, 14))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title(title)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename=\"model.pkl\"):\n",
    "    with open(filename, \"wb\") as file:\n",
    "        pickle.dump(model, file)\n",
    "    print(f\"Model saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename=\"model.pkl\"):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        model = pickle.load(file)\n",
    "    print(f\"Model loaded from {filename}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a pickle file            \n",
    "save_model(knn_model,\"models/knn.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3629354,
     "sourceId": 6308217,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
